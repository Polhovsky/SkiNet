{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "account_data_01 = pd.read_csv('results/dataset_analysis.csv', low_memory = False)\n",
    "clusters = pd.read_csv('results/clusters.csv', low_memory = False)\n",
    "account_data_02 = account_data_01.merge(clusters, on = 'image_id', how = 'inner')\n",
    "\n",
    "total_predictions = pd.read_csv('total_predictions.csv', low_memory = False)\n",
    "total_predictions = total_predictions[['image_id', 'y_hat']]\n",
    "total_predictions = pd.get_dummies(total_predictions, columns = ['y_hat'])\n",
    "\n",
    "account_data_03 = account_data_02.merge(total_predictions, on = 'image_id', how = 'inner')\n",
    "\n",
    "print('Number of samples in account_data_01:', account_data_01.shape[0])\n",
    "print('Number of samples in account_data_02:', account_data_02.shape[0])\n",
    "print('Number of samples in account_data_03:', account_data_03.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import image_ids in the training, validation and test set\n",
    "image_ids_train = pd.read_csv('results/image_ids_train.csv', low_memory = False)\n",
    "image_ids_val = pd.read_csv('results/image_ids_val.csv', low_memory = False)\n",
    "image_ids_test = pd.read_csv('results/image_ids_test.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct a training, validation and test set\n",
    "total_train = account_data_03.merge(image_ids_train, on = 'image_id', how = 'inner')\n",
    "total_val = account_data_03.merge(image_ids_val, on = 'image_id', how = 'inner')\n",
    "total_test = account_data_03.merge(image_ids_test, on = 'image_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_ids_test2 = total_test[['image_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's create a feature matrix and a target variable\n",
    "X_train = total_train.drop(['likes_groups', 'log_likes_image_corrected', 'likes_image_corrected', 'cluster', 'image_id', 'resort', 'accountname'], axis = 1)\n",
    "X_val = total_val.drop(['likes_groups', 'log_likes_image_corrected', 'likes_image_corrected', 'cluster', 'image_id', 'resort', 'accountname'], axis = 1)\n",
    "X_test = total_test.drop(['likes_groups', 'log_likes_image_corrected', 'likes_image_corrected', 'cluster', 'image_id', 'resort', 'accountname'], axis = 1)\n",
    "\n",
    "Y_train = total_train['likes_groups'].apply(lambda x: int(str(x)[0]))\n",
    "Y_val = total_val['likes_groups'].apply(lambda x: int(str(x)[0]))\n",
    "Y_test = total_test['likes_groups'].apply(lambda x: int(str(x)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_relevant_df = pd.read_csv('results/features_relevant_logistic_regression.csv', low_memory = False)\n",
    "nested_features_relevant_list = features_relevant_df.values.tolist()\n",
    "\n",
    "features_relevant_list = [item for sublist in nested_features_relevant_list for item in sublist]\n",
    "extra_features = ['y_hat_0', 'y_hat_1', 'y_hat_2', 'y_hat_3', 'y_hat_4', 'y_hat_5', 'y_hat_6', 'y_hat_7']\n",
    "features_list = features_relevant_list + extra_features\n",
    "len(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's scale the data (mean of zero and standard deviation of one) as input to a logistic regression for\n",
    "# maximum interpretability of the results and perform a sanity check to see whether each feature has in fact\n",
    "# a mean of zero and standard deviation one\n",
    "\n",
    "X_train_selection = X_train[features_list]\n",
    "X_val_selection = X_val[features_list]\n",
    "X_test_selection = X_test[features_list]\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_selection)\n",
    "\n",
    "X_train_selection_scaled = scaler.transform(X_train_selection)\n",
    "X_val_selection_scaled = scaler.transform(X_val_selection)\n",
    "X_test_selection_scaled = scaler.transform(X_test_selection)\n",
    "\n",
    "print('Information about the training set:\\n')\n",
    "print('   - datatype:', X_train_selection_scaled.dtype)\n",
    "print('   - shape of the dataset:', X_train_selection_scaled.shape)\n",
    "print('   - sum of the means of the columns:', round(X_train_selection_scaled.mean(axis = 0).sum(), 2))\n",
    "print('   - sum of the standard deviations of the columns:', round(X_train_selection_scaled.std(axis = 0).sum(), 2))\n",
    "print('\\n')\n",
    "print('Information about the validation set:\\n')\n",
    "print('   - datatype:', X_val_selection_scaled.dtype)\n",
    "print('   - shape of the dataset:', X_val_selection_scaled.shape)\n",
    "print('   - sum of the means of the columns:', round(X_val_selection_scaled.mean(axis = 0).sum(), 2))\n",
    "print('   - sum of the standard deviations of the columns:', round(X_val_selection_scaled.std(axis = 0).sum(), 2))\n",
    "print('\\n')\n",
    "print('Information about the test set:\\n')\n",
    "print('   - datatype:', X_test_selection_scaled.dtype)\n",
    "print('   - shape of the dataset:', X_test_selection_scaled.shape)\n",
    "print('   - sum of the means of the columns:', round(X_test_selection_scaled.mean(axis = 0).sum(), 2))\n",
    "print('   - sum of the standard deviations of the columns:', round(X_test_selection_scaled.std(axis = 0).sum(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a logistic regression classifier and output the accuracy for both the training and validation set\n",
    "\n",
    "clf = LogisticRegression(multi_class = 'multinomial', solver = 'newton-cg', random_state = 0).fit(X_train_selection_scaled, Y_train)\n",
    "\n",
    "# accuracy for the training set\n",
    "Y_train_pred = clf.predict(X_train_selection_scaled)\n",
    "accuracy_train = accuracy_score(Y_train, Y_train_pred)\n",
    "\n",
    "# accuracy for the validation set\n",
    "Y_val_pred = clf.predict(X_val_selection_scaled)\n",
    "accuracy_validation = accuracy_score(Y_val, Y_val_pred)\n",
    "\n",
    "print('Accuracy on the training set:', \"{0:.2f}\".format(accuracy_train))\n",
    "print('Accuracy on the validation set:', \"{0:.2f}\".format(accuracy_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy for the test set\n",
    "Y_test_pred = clf.predict(X_test_selection_scaled)\n",
    "accuracy_test = accuracy_score(Y_test, Y_test_pred)\n",
    "\n",
    "print('Accuracy on the test set:', \"{0:.2f}\".format(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame(np.column_stack((X_train_selection.columns.values, clf.coef_.T)))\n",
    "coefficients.columns = ['feature', '1 - HH', '2 - H', '3 - M', '4 - L', '5 - LL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.initializers import he_uniform, glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "features = Sequential()\n",
    "features.add(Dense(64, input_shape = (X_train_selection_scaled.shape[1],), kernel_initializer = he_uniform(), name = 'dense1'))\n",
    "features.add(Activation('relu', name = 'activation1'))\n",
    "features.add(Dense(64, kernel_initializer = he_uniform(), name = 'dense2'))\n",
    "features.add(Activation('relu', name = 'activation2'))\n",
    "features.add(Dense(64, kernel_initializer = he_uniform(), name = 'dense3'))\n",
    "features.add(Activation('relu', name = 'activation3'))\n",
    "features.add(Dense(64, kernel_initializer = he_uniform(), name = 'dense4'))\n",
    "features.add(Activation('relu', name = 'activation4'))\n",
    "features.add(Dense(64, kernel_initializer = he_uniform(), name = 'dense5'))\n",
    "features.add(Activation('relu', name = 'activation5'))\n",
    "features.add(Dense(5, kernel_initializer = glorot_uniform(), name = 'dense6'))\n",
    "features.add(Activation('softmax', name = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train_one_hot = np_utils.to_categorical(Y_train)[:, 1:6]\n",
    "Y_val_one_hot = np_utils.to_categorical(Y_val)[:, 1:6]\n",
    "Y_test_one_hot = np_utils.to_categorical(Y_test)[:, 1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.compile(optimizer = Adam(lr = 1e-3), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "history_epochs_0_5 = features.fit(x = X_train_selection_scaled,\n",
    "                                  y = Y_train_one_hot,\n",
    "                                  epochs = 5,\n",
    "                                  batch_size = 16,\n",
    "                                  validation_data = (X_val_selection_scaled, Y_val_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.compile(optimizer = Adam(lr = 1e-4), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "history_epochs_5_10 = features.fit(x = X_train_selection_scaled,\n",
    "                                   y = Y_train_one_hot,\n",
    "                                   epochs = 5,\n",
    "                                   batch_size = 16,\n",
    "                                   validation_data = (X_val_selection_scaled, Y_val_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.compile(optimizer = Adam(lr = 1e-5), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "history_epochs_10_15 = features.fit(x = X_train_selection_scaled,\n",
    "                                    y = Y_train_one_hot,\n",
    "                                    epochs = 5,\n",
    "                                    batch_size = 16,\n",
    "                                    validation_data = (X_val_selection_scaled, Y_val_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = features.evaluate(x = X_test_selection_scaled, y = Y_test_one_hot)\n",
    "\n",
    "print('\\nLoss:', \"{0:.3f}\".format(score[0]))\n",
    "print('Test accuracy:', \"{0:.2f}%\".format(score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_pred = []\n",
    "\n",
    "for i in range(0, X_test_selection_scaled.shape[0]):\n",
    "    pred_i = np.argmax(features.predict(X_test_selection_scaled[i].reshape(1, 51))) + 1\n",
    "    Y_test_pred.append(pred_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "# visualizing the development of the loss and accuracy (of the last batch in every epoch) with respect to the epoch\n",
    "\n",
    "plt.figure()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 8, forward = True)\n",
    "    \n",
    "# custom line colors\n",
    "color_accuracy = '#FF9933'\n",
    "color_loss = '#0099FF'\n",
    "\n",
    "# number of epochs\n",
    "x = np.arange(1, 16, 1)\n",
    "\n",
    "plt.axvline(5, color = '#999999', linestyle = '--', zorder = 0)\n",
    "plt.axvline(10, color = '#999999', linestyle = '--', zorder = 0)\n",
    "\n",
    "# extract the series from the history\n",
    "y1 = history_epochs_0_5.history['acc'] + history_epochs_5_10.history['acc'] + history_epochs_10_15.history['acc']\n",
    "y2 = history_epochs_0_5.history['val_acc'] + history_epochs_5_10.history['val_acc'] + history_epochs_10_15.history['val_acc']\n",
    "y3 = history_epochs_0_5.history['loss'] + history_epochs_5_10.history['loss'] + history_epochs_10_15.history['loss']\n",
    "y4 = history_epochs_0_5.history['val_loss'] + history_epochs_5_10.history['val_loss'] + history_epochs_10_15.history['val_loss']\n",
    "\n",
    "ax1 = plt.gca()\n",
    "\n",
    "# plot the accuracy series\n",
    "accuracy_train, = plt.plot(x, y1, color_accuracy, linewidth = 0.75, linestyle = '-', zorder = 3)\n",
    "accuracy_validation, = plt.plot(x, y2, color_accuracy, linewidth = 0.75, linestyle = '--', zorder = 3)\n",
    "\n",
    "ax1.set_ylim([0, 1])\n",
    "yticks_major = np.round(np.linspace(0, 1, 11), 1)\n",
    "yticks_major_str = (yticks_major * 100).astype(int).astype(str).tolist()\n",
    "yticks_labels = [x + ' %' for x in yticks_major_str]\n",
    "ax1.set_yticks(yticks_major)\n",
    "ax1.set_yticklabels(yticks_labels, fontsize = 10)\n",
    "\n",
    "ax1.set_xlabel('epoch', fontsize = 11, labelpad = 10)\n",
    "ax1.set_ylabel('accuracy', fontsize = 11)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# plot the accuracy series\n",
    "loss_train, = plt.plot(x, y3, color_loss, linewidth = 0.75, linestyle = '-', zorder = 3)\n",
    "loss_validation, = plt.plot(x, y4, color_loss, linewidth = 0.75, linestyle = '--', zorder = 3)\n",
    "\n",
    "ax2.set_ylim([0, 3])\n",
    "ax2.set_ylabel('loss', fontsize = 11)\n",
    "ax1.grid(color = '#333333', linestyle = '--', linewidth = 0.25, zorder = 1)\n",
    "\n",
    "xticks_major = np.round(np.linspace(1, 19, 10), 2)\n",
    "ax1.set_xticks(xticks_major)\n",
    "ax1.set_xlim([0, 16])\n",
    "\n",
    "plt.title('\\nAccuracy and Loss\\n', fontsize = 14)\n",
    "\n",
    "plt.text(1, 1.35, 'Adam with lr = 1e-3', fontsize = 12, color = '#666666', multialignment = 'center')\n",
    "\n",
    "plt.annotate(\"\",\n",
    "             xy = (0.25, 1.5),\n",
    "             xytext = (4.75, 1.5),\n",
    "             arrowprops = dict(arrowstyle = \"<->\", facecolor = '#666666'))\n",
    "\n",
    "plt.text(6, 1.35, 'Adam with lr = 1e-4', fontsize = 12, color = '#666666', multialignment = 'center')\n",
    "\n",
    "plt.annotate(\"\",\n",
    "             xy = (5.25, 1.5),\n",
    "             xytext = (9.75, 1.5),\n",
    "             arrowprops = dict(arrowstyle = \"<->\", facecolor = '#666666'))\n",
    "\n",
    "plt.text(11, 1.35, 'Adam with lr = 1e-5', fontsize = 12, color = '#666666', multialignment = 'center')\n",
    "\n",
    "plt.annotate(\"\",\n",
    "             xy = (10.25, 1.5),\n",
    "             xytext = (14.75, 1.5),\n",
    "             arrowprops = dict(arrowstyle = \"<->\", facecolor = '#666666'))\n",
    "\n",
    "plt.legend([accuracy_train, accuracy_validation, loss_train, loss_validation],\n",
    "               ['accuracy training set',\n",
    "                'accuracy validation set',\n",
    "                'loss training set',\n",
    "                'loss validation set'],\n",
    "                loc = 2,\n",
    "                facecolor = 'white',\n",
    "                edgecolor = 'black',\n",
    "                borderaxespad = 1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "filename = 'results/accuracy_loss_final.png'\n",
    "fig.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confusion matrices, with and without normalization\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize = False, title = 'Confusion matrix', cmap = plt.cm.Blues):\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.colorbar()\n",
    "    if normalize:\n",
    "        plt.clim(-0, 1)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 fontsize = 20,\n",
    "                 horizontalalignment = \"center\",\n",
    "                 color = \"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test, Y_test_pred)\n",
    "np.set_printoptions(precision = 2)\n",
    "\n",
    "class_names = ['HH',\n",
    "               'H',\n",
    "               'M',\n",
    "               'L',\n",
    "               'LL']\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize = (10, 10))\n",
    "plot_confusion_matrix(cnf_matrix, classes = class_names, title = 'Confusion matrix, without normalization')\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "for i in range(0, len(class_names)):\n",
    "    accuracy = accuracy + cnf_matrix[i, i]\n",
    "\n",
    "print('\\nThe accuracy is:', accuracy / cnf_matrix.sum(), '\\n')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize = (10, 10))\n",
    "plot_confusion_matrix(cnf_matrix, classes = class_names, normalize = True, title = 'Normalized confusion matrix')\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "for i in range(0, len(class_names)):\n",
    "    accuracy = accuracy + cnf_matrix[i, i]\n",
    "\n",
    "print('\\nThe accuracy is:', accuracy / cnf_matrix.sum())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's add the predictions to the features to analyse a bit more\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for image_id, pred in zip(image_ids_test2['image_id'].values, Y_test_pred):\n",
    "    prediction = image_id, pred\n",
    "    predictions.append(prediction)\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.columns = ['image_id', 'prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the other features and select the relevant ones for this purpose\n",
    "predictions_df = account_data_03.merge(predictions_df, on = 'image_id', how = 'inner')\n",
    "predictions_df = predictions_df[['image_id', 'resort', 'cluster', 'likes_groups', 'prediction']]\n",
    "predictions_df['likes_groups'] = predictions_df['likes_groups'].apply(lambda x: int(str(x)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an overview of the predictions versus the original categories per resort\n",
    "overview = predictions_df.groupby(['resort', 'likes_groups', 'prediction']).image_id.count().reset_index().rename(columns = {'image_id': 'count'})\n",
    "overview['correct'] = np.where(overview['prediction'] == overview['likes_groups'], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_per_group = overview[['resort', 'correct', 'count']].groupby(['resort', 'correct']).sum().reset_index().rename(columns = {'count': 'count_per_group'})\n",
    "sum_total = overview[['resort', 'count']].groupby(['resort']).sum().reset_index().rename(columns = {'count': 'total'})\n",
    "percentage = sum_per_group.merge(sum_total, on = 'resort', how = 'outer')\n",
    "percentage['percentage'] = 100 * percentage['count_per_group'] / percentage['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_top10 = percentage[(percentage['total'] >= 100) & (percentage['correct'] == 1)].nlargest(10, 'percentage') \\\n",
    "                    .sort_values(by = 'percentage', ascending = False).set_index('resort')\n",
    "percentage_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_worst10 = percentage[percentage['correct'] == 1].nsmallest(10, 'percentage') \\\n",
    "                        .sort_values(by = 'percentage', ascending = False).set_index('resort')\n",
    "percentage_worst10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top10_resorts = percentage_top10.index.values.tolist()\n",
    "worst10_resorts = percentage_worst10.index.values.tolist()\n",
    "xticks_labels = [None] * (len(top10_resorts) + len(worst10_resorts))\n",
    "xticks_labels[::2] = top10_resorts\n",
    "xticks_labels[1::2] = worst10_resorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "fig = plt.figure(figsize = (12, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "index = np.linspace(0, 19, 10)\n",
    "bar_width = 0.6\n",
    "\n",
    "top10 = plt.bar(index,\n",
    "                percentage_top10['percentage'],\n",
    "                bar_width,\n",
    "                color = '#0099FF',\n",
    "                ec = 'black',\n",
    "                linewidth = 0.5)\n",
    "\n",
    "X = np.linspace(0, 19, 10)\n",
    "Y = np.array(percentage_top10['percentage'])\n",
    "Z1 = np.array(percentage_top10['count_per_group'])\n",
    "Z2 = np.array(percentage_top10['total'])\n",
    "\n",
    "for a, b, c, d in zip(X, Y, Z1, Z2): \n",
    "    plt.text(a + 0.05, b + 3, '[' + str(c) + ' / ' + str(d) + ']', fontsize = 8, ha = 'center', va = 'center')\n",
    "    \n",
    "worst10 = plt.bar(index + 1,\n",
    "                  percentage_worst10['percentage'],\n",
    "                  bar_width,\n",
    "                  color = '#FF9933',\n",
    "                  ec = 'black',\n",
    "                  linewidth = 0.5)\n",
    "\n",
    "X = np.linspace(1, 20, 10)\n",
    "Y = np.array(percentage_worst10['percentage'])\n",
    "Z1 = np.array(percentage_worst10['count_per_group'])\n",
    "Z2 = np.array(percentage_worst10['total'])\n",
    "\n",
    "for a, b, c, d in zip(X, Y, Z1, Z2): \n",
    "    plt.text(a + 0.05, b + 3, '[' + str(c) + ' / ' + str(d) + ']', fontsize = 8, ha = 'center', va = 'center')\n",
    "\n",
    "xticks_major = xticks_major = np.linspace(0, 20, 20)\n",
    "ax.set_xticks(xticks_major)\n",
    "ax.set_xticklabels(xticks_labels, fontsize = 10, rotation = 'vertical')\n",
    "\n",
    "plt.ylim(0, 110)\n",
    "yticks_major = np.round(np.linspace(0, 100, 11), 10)\n",
    "yticks_major_str = (yticks_major).astype(int).astype(str).tolist()\n",
    "yticks_labels = [x + ' %' for x in yticks_major_str]\n",
    "ax.set_yticks(yticks_major)\n",
    "ax.set_yticklabels(yticks_labels, fontsize = 10)\n",
    "ax.yaxis.grid(color = '#333333', alpha = 0.25, zorder = 1)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "legend = plt.legend([top10, worst10],\n",
    "                ['ten resorts with the highest accuracy',\n",
    "                'ten resorts with the lowest accuracy'],\n",
    "                fontsize = 8,\n",
    "                loc = 1,\n",
    "                facecolor = 'white',\n",
    "                edgecolor = 'black',\n",
    "                borderaxespad = 1)\n",
    "\n",
    "plt.suptitle('The ten resorts with the highest / lowest accuracy', fontsize = 14, y = 0.97)\n",
    "plt.title('(number of correct predictions versus number of samples in the test set in brackets)', fontsize = 10, y = 1.02)\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Accuracy', fontsize = 11)\n",
    "plt.show()\n",
    "\n",
    "filename = 'results/top10_worst10_final.png'\n",
    "fig.savefig(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
