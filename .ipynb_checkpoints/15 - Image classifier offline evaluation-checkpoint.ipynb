{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os.path\n",
    "import pickle\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import load_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('image_classifier_tl_5_ft_15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model summary with the output shapes and the number of parameters for each layer\n",
    "\n",
    "with open('results/image_classifier.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    model.summary(print_fn = lambda x: fh.write(x + '\\n'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "plot_model(model, to_file = 'results/image_classifier.png')\n",
    "SVG(model_to_dot(model).create(prog = 'dot', format = 'svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import test set with probabilities and predictions\n",
    "\n",
    "test_set_predictions = pd.read_csv('test_set_predictions.csv', low_memory = False)\n",
    "test_set_predictions['image_id'] = test_set_predictions['filename'].apply(lambda x: int(re.search('\\d+', x).group(0)))\n",
    "test_set_predictions.drop(['Unnamed: 0', 'filename'], axis = 1, inplace = True)\n",
    "test_set_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predictions = pd.read_csv('total_predictions.csv', low_memory = False)\n",
    "total_predictions.drop(['Unnamed: 0', 'filename'], axis = 1, inplace = True)\n",
    "total_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_test = test_set_predictions[['image_id', 'y_hat']]\n",
    "check_test.rename(columns = {'y_hat': 'y_hat_test'}, inplace = True)\n",
    "\n",
    "check_total = total_predictions[['image_id', 'y_hat']]\n",
    "check_total.rename(columns = {'y_hat': 'y_hat_total'}, inplace = True)\n",
    "\n",
    "overlap = check_total.merge(check_test, on = 'image_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap[overlap['y_hat_total'] == overlap['y_hat_test']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confusion matrices, with and without normalization\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize = False, title = 'Confusion matrix', cmap = plt.cm.Blues):\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.colorbar()\n",
    "    if normalize:\n",
    "        plt.clim(-0, 1)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 fontsize = 14,\n",
    "                 horizontalalignment = \"center\",\n",
    "                 color = \"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_set_predictions['y_true'], test_set_predictions['y_hat'])\n",
    "np.set_printoptions(precision = 2)\n",
    "\n",
    "class_names = ['Animals',\n",
    "               'Lifts',\n",
    "               'Other',\n",
    "               'People',\n",
    "               'Summer activity',\n",
    "               'Summer landscape',\n",
    "               'Winter activity',\n",
    "               'Winter landscape']\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize = (10, 10))\n",
    "plot_confusion_matrix(cnf_matrix, classes = class_names, title = 'Confusion matrix, without normalization')\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "for i in range(0, len(class_names)):\n",
    "    accuracy = accuracy + cnf_matrix[i, i]\n",
    "\n",
    "print('\\nThe accuracy is:', accuracy / cnf_matrix.sum(), '\\n')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize = (10, 10))\n",
    "plot_confusion_matrix(cnf_matrix, classes = class_names, normalize = True, title = 'Normalized confusion matrix')\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "for i in range(0, len(class_names)):\n",
    "    accuracy = accuracy + cnf_matrix[i, i]\n",
    "\n",
    "print('\\nThe accuracy is:', accuracy / cnf_matrix.sum())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the history files\n",
    "\n",
    "picklehistory = open('history_transfer.p', 'rb')\n",
    "history_transfer = pickle.load(picklehistory)\n",
    "picklehistory.close()\n",
    "\n",
    "picklehistory = open('history_finetune.p', 'rb')\n",
    "history_finetune = pickle.load(picklehistory)\n",
    "picklehistory.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the development of the loss function and accuracy, both for the training and the validation set\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "# visualizing the development of the loss and accuracy (of the last batch in every epoch) with respect to the epoch\n",
    "\n",
    "plt.figure()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 8, forward = True)\n",
    "    \n",
    "# custom line colors\n",
    "color_accuracy = '#FF9933'\n",
    "color_loss = '#0099FF'\n",
    "\n",
    "# number of epochs\n",
    "x = np.arange(1, 21, 1)\n",
    "\n",
    "# extract the series from the history\n",
    "y1 = history_transfer['acc'] + history_finetune['acc']\n",
    "y2 = history_transfer['val_acc'] + history_finetune['val_acc']\n",
    "y3 = history_transfer['loss'] + history_finetune['loss']\n",
    "y4 = history_transfer['val_loss'] + history_finetune['val_loss']\n",
    "\n",
    "ax1 = plt.gca()\n",
    "\n",
    "# plot the accuracy series\n",
    "accuracy_train, = plt.plot(x, y1, color_accuracy, linewidth = 0.75, linestyle = '-')\n",
    "accuracy_validation, = plt.plot(x, y2, color_accuracy, linewidth = 0.75, linestyle = '--')\n",
    "\n",
    "ax1.set_ylim([0, 1])\n",
    "yticks_major = np.round(np.linspace(0, 1, 11), 1)\n",
    "yticks_major_str = (yticks_major * 100).astype(int).astype(str).tolist()\n",
    "yticks_labels = [x + ' %' for x in yticks_major_str]\n",
    "ax1.set_yticks(yticks_major)\n",
    "ax1.set_yticklabels(yticks_labels, fontsize = 10)\n",
    "\n",
    "ax1.set_xlabel('epoch', fontsize = 11, labelpad = 10)\n",
    "ax1.set_ylabel('accuracy', fontsize = 11)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# plot the accuracy series\n",
    "loss_train, = plt.plot(x, y3, color_loss, linewidth = 0.75, linestyle = '-')\n",
    "loss_validation, = plt.plot(x, y4, color_loss, linewidth = 0.75, linestyle = '--')\n",
    "\n",
    "ax2.set_ylim([0, 3])\n",
    "ax2.set_ylabel('loss', fontsize = 11)\n",
    "ax1.grid(color = '#333333', linestyle = '--', linewidth = 0.25, zorder = 1)\n",
    "\n",
    "xticks_major = np.round(np.linspace(1, 19, 10), 2)\n",
    "ax1.set_xticks(xticks_major)\n",
    "ax1.set_xlim([0, 21])\n",
    "\n",
    "plt.title('\\nAccuracy and Loss\\n', fontsize = 14)\n",
    "\n",
    "plt.axvspan(0, 5, alpha = 0.075, color = '#0099FF', zorder = 0).set_hatch('/')\n",
    "plt.axvspan(5, 21, alpha = 0.075, color = '#FF9933', zorder = 0).set_hatch('/')\n",
    "\n",
    "plt.text(10.8, 1.45, 'fine-tuning', fontsize = 12, color = '#666666', multialignment = 'center')\n",
    "\n",
    "plt.annotate(\"\",\n",
    "             xy = (5.25, 1.6),\n",
    "             xytext = (20.75, 1.6),\n",
    "             arrowprops = dict(arrowstyle = \"<->\", facecolor = '#666666'))\n",
    "\n",
    "plt.text(1.7, 0.45, 'transfer\\nlearning', fontsize = 12, color = '#666666', multialignment = 'center')\n",
    "\n",
    "plt.annotate(\"\",\n",
    "             xy = (0.25, 0.7),\n",
    "             xytext = (4.75, 0.7),\n",
    "             arrowprops = dict(arrowstyle = \"<->\", facecolor = '#666666'))\n",
    "\n",
    "plt.legend([accuracy_train, accuracy_validation, loss_train, loss_validation],\n",
    "               ['accuracy training set',\n",
    "                'accuracy validation set',\n",
    "                'loss training set',\n",
    "                'loss validation set'],\n",
    "                loc = 2,\n",
    "                facecolor = 'white',\n",
    "                edgecolor = 'black',\n",
    "                borderaxespad = 1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "filename = 'results/accuracy_loss_image_classifier.png'\n",
    "fig.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict the class for all pictures\n",
    "\n",
    "account_data_01 = pd.read_csv('results/dataset_analysis.csv', low_memory = False)\n",
    "\n",
    "image_ids_train = pd.read_csv('results/image_ids_train.csv', low_memory = False)\n",
    "image_ids_val = pd.read_csv('results/image_ids_val.csv', low_memory = False)\n",
    "image_ids_test = pd.read_csv('results/image_ids_test.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_path_from_train_df(image_id, label):\n",
    "    image_path = 'training_data/' + str(label) + '/' + str(image_id) + '_256.jpg'\n",
    "    return image_path\n",
    "\n",
    "def file_path_from_validation_df(image_id, label):\n",
    "    image_path = 'validation_data/' + str(label) + '/' + str(image_id) + '_256.jpg'\n",
    "    return image_path\n",
    "\n",
    "def file_path_from_test_df(image_id, label):\n",
    "    image_path = 'test_data/' + str(label) + '/' + str(image_id) + '_256.jpg'\n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = account_data_01.merge(image_ids_train, on = 'image_id', how = 'inner')\n",
    "train_df = train_df[['image_id', 'likes_groups']]\n",
    "train_df['label'] = train_df.likes_groups.apply(lambda x: str(x)[0])\n",
    "train_df['path'] = train_df.apply(lambda x: file_path_from_train_df(x['image_id'], x['label']), axis = 1)\n",
    "\n",
    "validation_df = account_data_01.merge(image_ids_val, on = 'image_id', how = 'inner')\n",
    "validation_df = validation_df[['image_id', 'likes_groups']]\n",
    "validation_df['label'] = validation_df.likes_groups.apply(lambda x: str(x)[0])\n",
    "validation_df['path'] = validation_df.apply(lambda x: file_path_from_validation_df(x['image_id'], x['label']), axis = 1)\n",
    "\n",
    "test_df = account_data_01.merge(image_ids_test, on = 'image_id', how = 'inner')\n",
    "test_df = test_df[['image_id', 'likes_groups']]\n",
    "test_df['label'] = test_df.likes_groups.apply(lambda x: str(x)[0])\n",
    "test_df['path'] = test_df.apply(lambda x: file_path_from_test_df(x['image_id'], x['label']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_paths = list(zip(train_df['image_id'], train_df['path']))\n",
    "validation_paths = list(zip(validation_df['image_id'], validation_df['path']))\n",
    "test_paths = list(zip(test_df['image_id'], test_df['path']))\n",
    "\n",
    "paths = train_paths + validation_paths + test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_GAP = load_model('image_classifier_GAP.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# examples of correctly classified images\n",
    "img_path = 'image_classifier/test_data/Winter activity/600702_256.jpg'\n",
    "img = image.load_img(img_path, target_size = (224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "img1 = preprocess_input(x)\n",
    "\n",
    "img_path = 'image_classifier/test_data/People/3700675_256.jpg'\n",
    "img = image.load_img(img_path, target_size = (224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "img2 = preprocess_input(x)\n",
    "\n",
    "# examples of incorrectly classified images\n",
    "img_path = 'image_classifier/test_data/Summer activity/3701083_256.jpg'\n",
    "img = image.load_img(img_path, target_size = (224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "img3 = preprocess_input(x)\n",
    "\n",
    "img_path = 'image_classifier/Animals/1900249_256.jpg'\n",
    "img = image.load_img(img_path, target_size = (224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "img4 = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probabilities = model.predict(img4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_class = np.argmax(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_labels = ['animals', 'lifts', 'other', 'people', 'summer\\nactivity', 'summer\\nlandscape', 'winter\\nactivity', 'winter\\nlandscape']\n",
    "\n",
    "probabilities_df = pd.DataFrame(list(zip(class_labels, list(probabilities[0]))))\n",
    "probabilities_df.columns = ['class', 'probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top3_probs = probabilities_df.nlargest(3, columns = 'probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "plt.figure()\n",
    "fig = plt.gcf()\n",
    "\n",
    "fig.set_size_inches(3, 2)\n",
    "\n",
    "X = np.linspace(0, 1, 3)\n",
    "\n",
    "plt.barh(X,\n",
    "         top3_probs['probability'],\n",
    "         0.3,\n",
    "         edgecolor = None,\n",
    "         color = 'red')\n",
    "\n",
    "Y = np.round(np.array(top3_probs['probability']), 2)\n",
    "Y_100 = (Y * 100).astype('int')\n",
    "\n",
    "for a, b, c in zip(X, Y, Y_100): \n",
    "    plt.text(b + 0.1, a, str(c) + '%', fontsize = 8, ha = 'center', va = 'center')\n",
    "    \n",
    "plt.xlim([0, 1.5])\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.invert_yaxis()\n",
    "ax.xaxis.grid(color = '#333333', linestyle = '--', linewidth = 0.25)\n",
    "ax.set_yticks(X)\n",
    "ax.set_yticklabels(top3_probs['class'], fontsize = 8, ha = 'center', va = 'center', x = 0.90)\n",
    "ax.tick_params(axis = 'y', which = 'both', length = 0)\n",
    "\n",
    "# xticks_major = np.round(np.linspace(0, 1, 6), 1)\n",
    "# xticks_major_str = (xticks_major * 100).astype(int).astype(str).tolist()\n",
    "# xticks_labels = [x + '%' for x in xticks_major_str]\n",
    "# ax.set_xticks(xticks_major)\n",
    "# ax.set_xticklabels(xticks_labels, fontsize = 8)\n",
    "ax.set_xticks([])\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "plt.show()\n",
    "    \n",
    "# filename = 'results/histogram_likes_groups.png'\n",
    "# fig.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = utils.load_img('image_classifier/Winter activity/600702_256.jpg', target_size = (224, 224))\n",
    "img2 = utils.load_img('image_classifier/People/1600710_256.jpg', target_size = (224, 224))\n",
    "\n",
    "f, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(img1)\n",
    "ax[1].imshow(img2)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
