{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os.path\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "import cv2\n",
    "\n",
    "# cv2.calcHist has the following parameters:(images, number of channels, mask, histSize, ranges[, hist[, accumulate]])\n",
    "#    - images:              it is the source image of type uint8 or float32, it should be given in square brackets\n",
    "#    - number  of channels: it is also given in square brackets, it is the index of channel for which we calculate histogram\n",
    "#                                - if input is grayscale image, its value is [0]\n",
    "#                                - if input is color image, you can pass [0], [1] or [2] to calculate histogram of blue,\n",
    "#                                  green or red channel\n",
    "#    - mask:                mask image, to find histogram of full image, it is given as \"None\" but if you want to find\n",
    "#                           histogram of particular region of image, you have to create a mask image for that and give\n",
    "#                           it as mask\n",
    "#    - histSize:            this represents our BIN count, it should be given in square brackets (full scale -> [256]) \n",
    "#    - ranges:              this is our RANGE, normally it is [0, 256].\n",
    "\n",
    "# first we create a matrix with features, in this case the histogram of each picture\n",
    "\n",
    "account_data_01 = pd.read_csv('results/dataset_analysis.csv', low_memory = False)\n",
    "\n",
    "print('Number of records in account_data_01:', account_data_01.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a list with only image_id and accountname for each picture\n",
    "image_list = account_data_01[['image_id', 'accountname']].values.tolist()\n",
    "\n",
    "X = np.array([])\n",
    "Y = np.array([])\n",
    "\n",
    "# import a picture and calculate the histogram for the different channels\n",
    "for j in range(0, len(image_list)):\n",
    "    \n",
    "    # define the location of the pictures of a particular resort\n",
    "    folder_path = 'images/{}/'.format(str(image_list[j][1]))\n",
    "\n",
    "    # import the picture if it exists\n",
    "    if os.path.isfile(folder_path + '/crop/' + str(image_list[j][0]) + str('_256.jpg')):\n",
    "        img = Image.open(folder_path + '/crop/' + str(image_list[j][0]) + str('_256.jpg'))\n",
    "        \n",
    "        # convert picture to an array\n",
    "        arr = np.array(img)\n",
    "        \n",
    "        # calculate the histograms\n",
    "        hist = cv2.calcHist([arr], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]).flatten().reshape(1, -1)\n",
    "        \n",
    "        # adding the concatenated histograms of this picture to the other ones\n",
    "        X = np.vstack([X, hist]) if X.size else hist\n",
    "        \n",
    "        # saving the image_id corresponding to the histograms for later use\n",
    "        image_id = int(image_list[j][0])\n",
    "        Y = np.append([Y], image_id)\n",
    "\n",
    "        # print the progress of the import\n",
    "        if (j > 0) and (j%5000) == 0:\n",
    "            print(j, 'images have been processed')\n",
    "\n",
    "# make Y 2-dimensional\n",
    "Y = Y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save datasets as pickle file\n",
    "pickleX = open('results/cluster_X_3D_8bins.p', 'wb')\n",
    "pickle.dump(X, pickleX, -1)\n",
    "pickleX.close()\n",
    "\n",
    "pickleY = open('results/cluster_Y_3D_8bins.p', 'wb')\n",
    "pickle.dump(Y, pickleY, -1)\n",
    "pickleY.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle files\n",
    "pickleX = open('results/cluster_X_3D_8bins.p', 'rb')\n",
    "X = pickle.load(pickleX)\n",
    "pickleX.close()\n",
    "\n",
    "pickleY = open('results/cluster_Y_3D_8bins.p', 'rb')\n",
    "Y = pickle.load(pickleY)\n",
    "pickleY.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 50% of the dataset, KMeans will crash on the full dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.5, train_size = 0.5, random_state = 0)\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's select two pictures, a typical non winter picture and a typical winter picture, manually\n",
    "(Y == 3900412).sum(), (Y == 3400094).sum(), np.where(Y == 3900412)[0][0], np.where(Y == 3400094)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a typical non-winter picture\n",
    "image_list = account_data_01[['image_id', 'accountname']].values.tolist()\n",
    "\n",
    "non_winter_id = 8186\n",
    "winter_id = 39640\n",
    "\n",
    "folder_path = 'images/{}/'.format(str(image_list[non_winter_id][1]))\n",
    "img_non_winter = Image.open(folder_path + '/crop/' + str(image_list[non_winter_id][0]) + str('_256.jpg'))\n",
    "arr_non_winter = np.array(img_non_winter)\n",
    "\n",
    "print('Picture non-winter:', arr_non_winter.shape, Y[non_winter_id])\n",
    "                 \n",
    "plt.imshow(arr_non_winter)\n",
    "plt.show()\n",
    "\n",
    "folder_path = 'images/{}/'.format(str(image_list[winter_id][1]))\n",
    "img_winter = Image.open(folder_path + '/crop/' + str(image_list[winter_id][0]) + str('_256.jpg'))\n",
    "arr_winter = np.array(img_winter)\n",
    "\n",
    "print('Picture winter:', arr_winter.shape, Y[winter_id])\n",
    "                 \n",
    "plt.imshow(arr_winter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the histogram distributions of two different pictures\n",
    "observations = np.arange(1, 513, 1)\n",
    "\n",
    "plt.figure()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 8)\n",
    "\n",
    "non_winter, = plt.plot(observations, X[non_winter_id, :], color = '#FF9933', linewidth = 0.75, linestyle = '-')\n",
    "winter, = plt.plot(observations, X[winter_id, :], color = '#0099FF', linewidth = 0.75, linestyle = '-')\n",
    "\n",
    "plt.title(('\\nHistogram distributions of two pictures\\n'), fontsize = 14)\n",
    "plt.xlabel('color bins across 3 channels (BGR)', fontsize = 11, labelpad = 10)\n",
    "plt.ylabel('Number of pixels', fontsize = 11)\n",
    "\n",
    "legend = plt.legend([non_winter, winter],\n",
    "               ['non-winter picture',\n",
    "                'winter picture'],\n",
    "                loc = 2,\n",
    "                facecolor = 'white',\n",
    "                edgecolor = 'black',\n",
    "                borderaxespad = 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create two initial centroids: one for summer and one for winter pictures\n",
    "init_clusters = np.vstack((X[non_winter_id], X[winter_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_sample_standardized = scaler.transform(X_train)\n",
    "\n",
    "range_n_clusters = [2]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    \n",
    "    # create a subplot with 1 row and 2 columns\n",
    "    plt.figure()\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(10, 7)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # the 1st subplot is the silhouette plot\n",
    "    # the silhouette coefficient can range from -1, 1 but let's focus on the following range: [-0.2, 1]\n",
    "    ax.set_xlim([-0.2, 1])\n",
    "    \n",
    "    # the (n_clusters + 1) * 10 is for inserting blank space between silhouette plots of individual clusters,\n",
    "    ax.set_ylim([0, len(X_sample_standardized) + (n_clusters + 1) * 10])\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    clusterer = KMeans(n_clusters = n_clusters,\n",
    "                       algorithm = 'elkan',\n",
    "                       max_iter = 100,\n",
    "                       init = 'k-means++',\n",
    "                       n_init = 10)\n",
    "    \n",
    "    kmeans = clusterer.fit_predict(X_sample_standardized)\n",
    "\n",
    "    # the silhouette_score gives the average value for all the samples\n",
    "    #    -> this gives a perspective into the density and separation of the formed clusters\n",
    "    silhouette_avg = silhouette_score(X_sample_standardized, kmeans)\n",
    "    \n",
    "    # compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X_sample_standardized, kmeans)\n",
    "    \n",
    "    y_lower = 10\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        \n",
    "        # aggregate the silhouette scores for samples belonging to cluster i and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[kmeans == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.spectral(float(i) / n_clusters)\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                         0,\n",
    "                         ith_cluster_silhouette_values,\n",
    "                         facecolor = color,\n",
    "                         edgecolor = color,\n",
    "                         alpha = 0.5)\n",
    "\n",
    "        # label the silhouette plots with their cluster numbers at the middle\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax.set_title(('\\nSilhouette analysis for KMeans clustering with %i clusters\\n' %n_clusters), fontsize = 14)\n",
    "    ax.set_xlabel('Silhouette coefficient values', fontsize = 11, labelpad = 10)\n",
    "    ax.set_ylabel('Cluster label', fontsize = 11)\n",
    "\n",
    "    # the vertical line for average silhouette score of all the values\n",
    "    ax.axvline(x = silhouette_avg, color = 'red', linestyle = '--')\n",
    "\n",
    "    # clear the yaxis labels / ticks\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    ax.grid(color = 'grey', linestyle = '--', linewidth = 0.25)\n",
    "    plt.show()\n",
    "    \n",
    "    filename = 'results/silhouette_plot.png'\n",
    "    fig.savefig(filename)\n",
    "    \n",
    "    print('For', n_clusters, 'clusters the average silhouette_score is:', silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusterer.fit(X_sample_standardized).labels_.reshape(-1, 1)\n",
    "unique, counts = np.unique(clusters, return_counts = True)\n",
    "\n",
    "print('The number of samples in each cluster:\\n', np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusterer.labels_.reshape(-1, 1)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples in cluster 1\n",
    "Y_train[np.where(clusters == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the indices of some of these pictures\n",
    "np.where(Y == 6800766)[0][0], np.where(Y == 5200776)[0][0], np.where(Y == 401550)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see these pictures\n",
    "cluster_1_image_ids = [20451, 48420, 32103]\n",
    "\n",
    "for cluster_1_image_id in cluster_1_image_ids:\n",
    "\n",
    "    folder_path = 'images/{}/'.format(str(image_list[cluster_1_image_id][1]))\n",
    "    img = Image.open(folder_path + '/crop/' + str(image_list[cluster_1_image_id][0]) + str('_256.jpg'))\n",
    "    arr = np.array(img)\n",
    "\n",
    "    print('Picture example cluster 0:', arr.shape, Y[cluster_1_image_id])\n",
    "\n",
    "    plt.imshow(arr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples in cluster 0\n",
    "Y_train[np.where(clusters == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the indices of some of these pictures\n",
    "np.where(Y == 2600232)[0][0], np.where(Y == 1401150)[0][0], np.where(Y == 3100120)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see these pictures\n",
    "cluster_0_image_ids = [41748, 49528, 2732]\n",
    "\n",
    "for cluster_0_image_id in cluster_0_image_ids:\n",
    "\n",
    "    folder_path = 'images/{}/'.format(str(image_list[cluster_0_image_id][1]))\n",
    "    img = Image.open(folder_path + '/crop/' + str(image_list[cluster_0_image_id][0]) + str('_256.jpg'))\n",
    "    arr = np.array(img)\n",
    "\n",
    "    print('Picture example cluster 1:', arr.shape, Y[cluster_0_image_id])\n",
    "\n",
    "    plt.imshow(arr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cluster analysis is done on a random sample of 50% of the full dataset, let's assign every sample\n",
    "# to a cluster and save the results\n",
    "\n",
    "clusters_full_dataset = clusterer.predict(X).reshape(-1, 1)\n",
    "unique, counts = np.unique(clusters_full_dataset, return_counts = True)\n",
    "\n",
    "print('The number of samples in each cluster:\\n', np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_df = pd.DataFrame(np.hstack((clusters_full_dataset, Y)))\n",
    "cluster_df.columns = ['cluster', 'image_id']\n",
    "cluster_df.to_csv('results/clusters.csv', sep = ',', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
