{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "# the following features will be in the resort specific dataset:\n",
    "#    - dummy for every resort\n",
    "#    - number of pictures\n",
    "#    - number of followers\n",
    "#    - dummy for every state\n",
    "#    - PAF (Pure Awesomeness Factor from ZRankings)\n",
    "#    - ranking within the state based on PAF\n",
    "#    - population aggregated by state and by 3-, 4- and 5-digit zip codes and split by gender and age groups\n",
    "#    - general weather statistics (precipitation, minimum temperature and maximum temperature, snowfall\n",
    "#      and snow score preservation (preservation of snowpack due to exposure, altitude, latitude and rain incidence))\n",
    "\n",
    "# stats_table contains the following features:\n",
    "#    - name of resort -> convert into dummies with 'get_dummies'\n",
    "#    - number of pictures\n",
    "#    - number of followers\n",
    "#    - state -> convert into dummies with 'get_dummies'\n",
    "#    - zip code in order to merge the population data\n",
    "#    - latitude and longitude in order to calculate distance to weather station\n",
    "\n",
    "account_01 = pd.read_csv('results/stats_table.csv', sep = ',', encoding = \"ISO-8859-1\")\n",
    "account_01['zip_code_5digits'] = account_01['zip_code'].apply(lambda x: str(x).zfill(5))\n",
    "account_01['zip_code_4digits'] = account_01['zip_code_5digits'].apply(lambda x: x[0:4])\n",
    "account_01['zip_code_3digits'] = account_01['zip_code_5digits'].apply(lambda x: x[0:3])\n",
    "\n",
    "# import minimum and maximum elevation of every resort in order to calculate\n",
    "# the difference in elevation with each weather station\n",
    "\n",
    "elevation = pd.read_csv('other_data/resorts_elevation.csv', sep = ',', encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Silverton is not present in the ZRankings and will be therefore be excluded from the analysis\n",
    "elevation = elevation[elevation['resort'] != 'Silverton']\n",
    "elevation = elevation[['resort', 'min elevation (m)', 'max elevation (m)']]\n",
    "elevation.rename(columns = {'min elevation (m)': 'minimum_elevation',\n",
    "                            'max elevation (m)': 'maximum_elevation'}, inplace = True)\n",
    "\n",
    "# resorts with few pictures or without an Instagram account will be excluded from the analysis\n",
    "# Aspen Highlands, Aspen Mountain and Aspen Buttermilk have one Instagram account which will be merged to one ranking\n",
    "# Squaw Valley and Alpine Meadows have one Instagram account which will be merged to one ranking\n",
    "ZRankings = pd.read_csv('other_data/ZRankings.csv', sep = ',', encoding = \"ISO-8859-1\")\n",
    "ZRankings = ZRankings[(ZRankings['country'] == 'United States') & \n",
    "                      (ZRankings['remarks'].isin([np.nan,\n",
    "                                                  'average of Aspen Mountain and Aspen Highlands',\n",
    "                                                  'average of Squaw Valley and Alpine Meadows']))]\n",
    "\n",
    "ZRankings = ZRankings[['resort', 'PAF', 'overall', 'region', 'state', 'average yearly snowfall (cm)', 'total snow score preservation']]\n",
    "ZRankings.rename(columns = {'overall': 'ranking_overall',\n",
    "                            'region': 'ranking_region',\n",
    "                            'state': 'ranking_state',\n",
    "                            'average yearly snowfall (cm)': 'average_yearly_snowfall',\n",
    "                            'total snow score preservation': 'tss_preservation'}, inplace = True)\n",
    "\n",
    "print('The number of resorts in account is:', account_01.resort.count())\n",
    "print('The number of resorts in elevation is:', elevation.resort.count())\n",
    "print('The number of resorts in account is:', ZRankings.resort.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge account data with elevation and ZRankings data\n",
    "\n",
    "account_02 = account_01.merge(elevation, on = 'resort', how = 'inner')\n",
    "account_03 = account_02.merge(ZRankings, on = 'resort', how = 'inner')\n",
    "\n",
    "print('The number of resorts in account_01 is:', account_01.resort.count())\n",
    "print('The number of resorts in account_02 is:', account_02.resort.count())\n",
    "print('The number of resorts in account_03 is:', account_03.resort.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the population data\n",
    "\n",
    "zip_code_state = pd.read_csv('other_data/us_postal_codes.csv', sep = ',')\n",
    "zip_code_state = zip_code_state[['Zip Code', 'State']]\n",
    "zip_code_state.rename(columns = {'Zip Code': 'zip_code', 'State': 'state'}, inplace = True)\n",
    "zip_code_state.head()\n",
    "\n",
    "# 59% of people between 18 and 29 use Instagram, 33% of 30-49 year olds use Instagram\n",
    "# Instagram is more popular by women (38% of online women use Instagram versus 28% of online men)\n",
    "# source: https://sproutsocial.com/insights/new-social-media-demographics/#instagram...\n",
    "\n",
    "population_zip_code = pd.read_csv('other_data/population_by_zip_2010.csv', sep = ',')\n",
    "\n",
    "# population between 18 and 29 split by gender and zipcode\n",
    "\n",
    "population_zip_code_18_29 = population_zip_code[population_zip_code['minimum_age'].isin([18, 20, 21, 22, 25])] \\\n",
    "            .groupby(['zipcode', 'gender']).population.sum() \\\n",
    "            .to_frame().reset_index()\n",
    "\n",
    "population_zip_code_18_29 = population_zip_code_18_29.pivot_table(index = 'zipcode',\n",
    "                                                                  columns = 'gender',\n",
    "                                                                  values = 'population') \\\n",
    "            .reset_index() \\\n",
    "            .rename_axis(None, axis = 1)\n",
    "\n",
    "population_zip_code_18_29['total'] = population_zip_code_18_29['female'] + population_zip_code_18_29['male']\n",
    "population_zip_code_18_29.rename(columns = {'zipcode': 'zip_code',\n",
    "                                            'female': 'female_18_29',\n",
    "                                            'male': 'male_18_29',\n",
    "                                            'total': 'total_18_29'}, inplace = True)\n",
    "\n",
    "# population between 30 and 49 split by gender and zipcode\n",
    "\n",
    "population_zip_code_30_49 = population_zip_code[population_zip_code['minimum_age'].isin([30, 35, 40, 45])] \\\n",
    "            .groupby(['zipcode', 'gender']).population.sum() \\\n",
    "            .to_frame().reset_index()\n",
    "\n",
    "population_zip_code_30_49 = population_zip_code_30_49.pivot_table(index = 'zipcode',\n",
    "                                                                  columns = 'gender',\n",
    "                                                                  values = 'population') \\\n",
    "            .reset_index() \\\n",
    "            .rename_axis(None, axis = 1)\n",
    "\n",
    "population_zip_code_30_49['total'] = population_zip_code_30_49['female'] + population_zip_code_30_49['male']\n",
    "population_zip_code_30_49.rename(columns = {'zipcode': 'zip_code',\n",
    "                                            'female': 'female_30_49',\n",
    "                                            'male': 'male_30_49',\n",
    "                                            'total': 'total_30_49'}, inplace = True)\n",
    "\n",
    "# total population split by gender and zipcode\n",
    "\n",
    "population_zip_code_total = population_zip_code[(population_zip_code['minimum_age'].isnull()) & \n",
    "                    (population_zip_code['maximum_age'].isnull())] \\\n",
    "            .groupby(['zipcode', 'gender']).population.sum() \\\n",
    "            .to_frame().reset_index()\n",
    "\n",
    "population_zip_code_total = population_zip_code_total.pivot_table(index = 'zipcode',\n",
    "                                                                  columns = 'gender',\n",
    "                                                                  values = 'population') \\\n",
    "            .reset_index() \\\n",
    "            .rename_axis(None, axis = 1)\n",
    "        \n",
    "population_zip_code_total['total'] = population_zip_code_total['female'] + population_zip_code_total['male']\n",
    "population_zip_code_total.rename(columns = {'zipcode': 'zip_code',\n",
    "                                            'female': 'female_total',\n",
    "                                            'male': 'male_total',\n",
    "                                            'total': 'total_total'}, inplace = True)\n",
    "\n",
    "# merging populations\n",
    "populations = population_zip_code_18_29.merge(population_zip_code_30_49, on = 'zip_code', how = 'inner').merge(population_zip_code_total, on = 'zip_code', how = 'inner')\n",
    "\n",
    "print('The number of records in 18-29 is:', population_zip_code_18_29.zip_code.count())\n",
    "print('The number of records in 30-49 is:', population_zip_code_30_49.zip_code.count())\n",
    "print('The number of records in total is:', population_zip_code_total.zip_code.count())\n",
    "print('The number of records after the first merge:', populations.zip_code.count())\n",
    "\n",
    "# merging the state to the zip code\n",
    "populations = populations.merge(zip_code_state, on = 'zip_code', how = 'left')\n",
    "\n",
    "print('The number of records after the second merge:', populations.zip_code.count())\n",
    "\n",
    "# populations by state\n",
    "populations_state = populations.groupby('state').sum().reset_index()\n",
    "populations_state.drop('zip_code', axis = 1, inplace = True)\n",
    "populations_state.rename(columns = {'female_18_29': 'female_18_29_state',\n",
    "                                    'male_18_29':   'male_18_29_state',\n",
    "                                    'total_18_29':  'total_18_29_state',\n",
    "                                    'female_30_49': 'female_30_49_state',\n",
    "                                    'male_30_49':   'male_30_49_state',\n",
    "                                    'total_30_49':  'total_30_49_state',\n",
    "                                    'female_total': 'female_total_state',\n",
    "                                    'male_total':   'male_total_state',\n",
    "                                    'total_total':  'total_total_state'}, inplace = True)\n",
    "\n",
    "# change New Mexico to New_Mexico in order to merge\n",
    "populations_state.replace(to_replace = 'New Mexico', value = 'New_Mexico', inplace = True)\n",
    "\n",
    "# populations per zip code based on 3 -, 4 - and 5 digits\n",
    "populations['zip_code_5digits'] = populations['zip_code'].apply(lambda x: str(x).zfill(5))\n",
    "populations['zip_code_4digits'] = populations['zip_code_5digits'].apply(lambda x: x[0:4])\n",
    "populations['zip_code_3digits'] = populations['zip_code_5digits'].apply(lambda x: x[0:3])\n",
    "\n",
    "populations_3_digits = populations.groupby('zip_code_3digits').sum()\n",
    "populations_3_digits.drop('zip_code', axis = 1, inplace = True)\n",
    "populations_3_digits.columns = [str(col) + '_3_digits' for col in populations_3_digits.columns]\n",
    "populations_3_digits.reset_index(inplace = True)\n",
    "\n",
    "populations_4_digits = populations.groupby('zip_code_4digits').sum()\n",
    "populations_4_digits.drop('zip_code', axis = 1, inplace = True)\n",
    "populations_4_digits.columns = [str(col) + '_4_digits' for col in populations_4_digits.columns]\n",
    "populations_4_digits.reset_index(inplace = True)\n",
    "\n",
    "populations_5_digits = populations.groupby('zip_code_5digits').sum()\n",
    "populations_5_digits.drop('zip_code', axis = 1, inplace = True)\n",
    "populations_5_digits.columns = [str(col) + '_5_digits' for col in populations_5_digits.columns]\n",
    "populations_5_digits.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge account data with population data\n",
    "\n",
    "account_04 = account_03.merge(populations_5_digits, on = 'zip_code_5digits', how = 'inner')\n",
    "account_05 = account_04.merge(populations_4_digits, on = 'zip_code_4digits', how = 'inner')\n",
    "account_06 = account_05.merge(populations_3_digits, on = 'zip_code_3digits', how = 'inner')\n",
    "account_07 = account_06.merge(populations_state, on = 'state', how = 'inner')\n",
    "\n",
    "print('The number of resorts in account_03 is:', account_03.resort.count())\n",
    "print('The number of resorts in account_04 is:', account_04.resort.count())\n",
    "print('The number of resorts in account_05 is:', account_05.resort.count())\n",
    "print('The number of resorts in account_06 is:', account_06.resort.count())\n",
    "print('The number of resorts in account_07 is:', account_07.resort.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the weather data\n",
    "\n",
    "# create empty dataframes to fill up later\n",
    "weather_total = pd.DataFrame()\n",
    "account_stats_total = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(account_02.values.tolist())):\n",
    "\n",
    "    # PRCP = Precipitation (inches)\n",
    "    # TMAX = Maximum temperature (degrees Fahrenheit)\n",
    "    # TMIN = Minimum temperature (degrees Fahrenheit)\n",
    "\n",
    "    weather_data = pd.read_csv('weather_data/weather_' + str(account_02.values.tolist()[i][2]) + '.csv', parse_dates = [5], dayfirst = True, low_memory = False)\n",
    "    weather_data['latitude_resort'] = account_02.values.tolist()[i][4]\n",
    "    weather_data['longitude_resort'] = account_02.values.tolist()[i][3]\n",
    "    weather_data['min_elevation'] = account_02.values.tolist()[i][13]\n",
    "    weather_data['max_elevation'] = account_02.values.tolist()[i][14]\n",
    "    \n",
    "    # there are some 'weird' values -> remove this low quality data (Alaska has some temperatures of -148 degrees F ...)\n",
    "    weather_data = weather_data[weather_data['TMAX'] > -147]\n",
    "    weather_data = weather_data[weather_data['TMIN'] > -147]\n",
    "    \n",
    "    # remove duplicates\n",
    "    weather_data.drop_duplicates(keep = 'first', inplace = True)\n",
    "    \n",
    "    print('Resort:', account_02.values.tolist()[i][1])\n",
    "    \n",
    "    # calculate the distance from the resort to every weather station in the file\n",
    "    \n",
    "    def haversine(lon1, lat1, lon2, lat2):\n",
    "\n",
    "        # convert decimal degrees to radians\n",
    "        lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "        \n",
    "        # haversine formula\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "        c = 2 * asin(sqrt(a))\n",
    "        r = 6371 # radius of earth in kilometers (use 3956 for miles)\n",
    "        \n",
    "        return c * r\n",
    "    \n",
    "    weather_data['DISTANCE'] = weather_data.apply(lambda row: haversine(lon1 = row['LONGITUDE'],\n",
    "                                                                        lat1 = row['LATITUDE'],\n",
    "                                                                        lon2 = row['longitude_resort'],\n",
    "                                                                        lat2 = row['latitude_resort']), axis = 1)\n",
    "    \n",
    "    # calculate the difference in elevation between the weather station and mid-mountain of the resort,\n",
    "    # a positive number indicates a higher elevation of the weather station\n",
    "    weather_data['ELEVATION_DIFFERENCE'] = (weather_data['ELEVATION'] - ((weather_data['max_elevation'] + weather_data['min_elevation']) / 2)) / 1000\n",
    "\n",
    "    weather_data['DATE'] = pd.to_datetime(weather_data['DATE'])\n",
    "    \n",
    "    # select only data between Jan 01, 2011 and Dec 31, 2016 so all statistics are based on the same data and have similar quality\n",
    "    weather_data = weather_data[(weather_data['DATE'] >= datetime.date(2011, 1, 1)) & (weather_data['DATE'] <= datetime.date(2016, 12, 31))]\n",
    "    \n",
    "    weather_data = weather_data[['STATION', 'DATE', 'PRCP', 'TMAX', 'TMIN', 'DISTANCE', 'ELEVATION_DIFFERENCE']]\n",
    "    weather_data.columns = ['station', 'date', 'precipitation_inches', 'temp_max', 'temp_min', 'distance', 'elevation_difference']\n",
    "    \n",
    "    # convert precipitation to mm and temperatures to degrees Celsius\n",
    "    weather_data['precipitation_mm'] = weather_data['precipitation_inches'] * 2.54 * 10\n",
    "    weather_data['temp_max_celsius'] = (weather_data['temp_max'] - 32) * 5 / 9\n",
    "    weather_data['temp_min_celsius'] = (weather_data['temp_min'] - 32) * 5 / 9\n",
    "\n",
    "    weather_stats = ['precipitation_mm', 'temp_max_celsius', 'temp_min_celsius']\n",
    "    \n",
    "    # create empty dataframes to fill up later\n",
    "    weather_resort = pd.DataFrame()\n",
    "    account_stats_resort = pd.DataFrame()\n",
    "    \n",
    "    for weather_stat in weather_stats:\n",
    "                        \n",
    "        # select nearest available observation for the weather statistic\n",
    "        min_per_day = weather_data[weather_data[weather_stat].notnull()].groupby('date')['distance'].min().to_frame().reset_index()\n",
    "        weather_data_optimum = weather_data.merge(min_per_day,\n",
    "                                                  left_on = ['date', 'distance'],\n",
    "                                                  right_on = ['date', 'distance'],\n",
    "                                                  how = 'inner')\n",
    "        \n",
    "        weather_data_optimum = weather_data_optimum[['date', 'distance', 'elevation_difference', weather_stat]]\n",
    "        print('Number of records in weather_data_optimum is:', weather_data_optimum.shape[0])\n",
    "        \n",
    "        weather_data_optimum.drop_duplicates(keep = 'first', inplace = True)\n",
    "        print('Number of records in weather_data_optimum after removing possible duplicates is:', weather_data_optimum.shape[0])\n",
    "        \n",
    "        # correct the temperature for the difference in elevation (6 degrees celsius per 1000 meters)\n",
    "        if (weather_stat == 'temp_max_celsius') | (weather_stat == 'temp_min_celsius'):\n",
    "            weather_data_optimum[weather_stat] = weather_data_optimum[weather_stat] + weather_data_optimum['elevation_difference'] * 6\n",
    "        \n",
    "        # if the number of records does not equal 2192 (the number of days in 2011 - 2016) the program will stop\n",
    "        if weather_data_optimum['date'].count() != 2192:\n",
    "            print('Number of records for', weather_stat, 'near', account_02.values.tolist()[i][1], 'does not equal 2192.')\n",
    "            exit()\n",
    "            \n",
    "        # save both minimum and maximum distance as well as minimum and maximum elevation difference per weather statistic \n",
    "        min_distance = weather_data_optimum['distance'].min()\n",
    "        max_distance = weather_data_optimum['distance'].max()\n",
    "        \n",
    "        account_stats_temp = [account_01.values.tolist()[i][1],\n",
    "                              weather_stat,\n",
    "                              min_distance,\n",
    "                              max_distance]\n",
    "        \n",
    "        account_stats_temp_df = pd.DataFrame(account_stats_temp).T\n",
    "   \n",
    "        # calculate the averages for every month of the year (1 - 12)\n",
    "        weather_data_optimum['month'] = weather_data_optimum['date'].apply(lambda x: x.month)\n",
    "        \n",
    "        weather_temp = weather_data_optimum.pivot_table(index = None, \n",
    "                                                        columns = 'month', \n",
    "                                                        values = weather_stat, \n",
    "                                                        fill_value = 0, \n",
    "                                                        aggfunc = 'mean').reset_index()\n",
    "        \n",
    "        weather_temp.columns = [str(weather_stat) + '_' + str(col) for col in weather_temp.columns]\n",
    "        weather_temp.drop([str(weather_stat) + '_index'], axis = 1, inplace = True)\n",
    "        \n",
    "        weather_resort = pd.concat([weather_resort, weather_temp], axis = 1)\n",
    "        weather_resort['resort'] = account_02.values.tolist()[i][1]\n",
    "        \n",
    "        account_stats_resort = pd.concat([account_stats_resort, account_stats_temp_df], axis = 0)\n",
    "        \n",
    "    weather_total = pd.concat([weather_total, weather_resort], axis = 0)\n",
    "    account_stats_total = pd.concat([account_stats_total, account_stats_resort], axis = 0)\n",
    "        \n",
    "    print('   OK!\\n')\n",
    "\n",
    "account_stats_total.columns = ['resort',\n",
    "                               'weather statistic',\n",
    "                               'minimum distance',\n",
    "                               'maximum distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the maximum distance per resort\n",
    "account_stats_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the statistics to a csv\n",
    "account_stats_total.to_csv('results/account_statistics_resorts.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_08 = account_07.merge(weather_total, on = 'resort', how = 'inner')\n",
    "\n",
    "print('The number of resorts in account_07 is:', account_07.resort.count())\n",
    "print('The number of resorts in account_08 is:', account_08.resort.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "account_09 = account_08.drop(['number_images_trash',\n",
    "                              'zip_code_5digits',\n",
    "                              'zip_code_4digits',\n",
    "                              'zip_code_3digits'], axis = 1)\n",
    "\n",
    "account_09['resort'] = account_09['resort'].astype('category')\n",
    "account_09['state'] = account_09['state'].astype('category')\n",
    "\n",
    "features_to_be_splitted = ['resort', 'state']\n",
    "\n",
    "account_10 = pd.get_dummies(account_09, prefix = None, columns = features_to_be_splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_10.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check a preview of the final dataframe\n",
    "account_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many missings does the final dataframe have?\n",
    "account_10.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the final dataframe to a csv\n",
    "account_10.to_csv('results/resort_specific_dataset.csv', sep = ',', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
