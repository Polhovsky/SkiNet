{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "from shutil import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools \n",
    "import operator\n",
    "\n",
    "classes_list = ['Animals',\n",
    "                'Food',\n",
    "                'Lifts',\n",
    "                'Other',\n",
    "                'People',\n",
    "                'Summer activity',\n",
    "                'Summer landscape',\n",
    "                'Winter activity',\n",
    "                'Winter landscape']\n",
    "\n",
    "images_total = []\n",
    "\n",
    "for i in range(0, len(classes_list)):\n",
    "    images_class = []\n",
    "    path = 'image_classifier/' + str(classes_list[i])\n",
    "    images_class = [[image, int(image[0:-8]), i] for image in listdir(path) if isfile(join(path, image))]\n",
    "    images_total = images_total + images_class\n",
    "    \n",
    "images_total_df = pd.DataFrame(images_total)\n",
    "images_total_df.columns = ['filename', 'image_id', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = images_total_df['filename']\n",
    "image_ids = images_total_df['image_id']\n",
    "classes = images_total_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training-, validation and test set\n",
    "\n",
    "filenames_temp, filenames_test, \\\n",
    "image_ids_temp, image_ids_test, \\\n",
    "classes_temp, classes_test = train_test_split(filenames,\n",
    "                                              image_ids,\n",
    "                                              classes,\n",
    "                                              stratify = classes,\n",
    "                                              test_size = 0.2,\n",
    "                                              train_size = 0.8,\n",
    "                                              random_state = 0)\n",
    "\n",
    "filenames_train, filenames_val, \\\n",
    "image_ids_train, image_ids_val, \\\n",
    "classes_train, classes_val = train_test_split(filenames_temp,\n",
    "                                              image_ids_temp,\n",
    "                                              classes_temp,\n",
    "                                              stratify = classes_temp,\n",
    "                                              test_size = 0.25,\n",
    "                                              train_size = 0.75,\n",
    "                                              random_state = 0)\n",
    "\n",
    "# print the number of examples in and dimensions of each set\n",
    "\n",
    "print ('filenames_train shape:', filenames_train.shape[0])\n",
    "print ('filenames_val shape:', filenames_val.shape[0])\n",
    "print ('filenames_test shape:', filenames_test.shape[0])\n",
    "\n",
    "print ('image_ids_train shape:', image_ids_train.shape)\n",
    "print ('image_ids_val shape:', image_ids_val.shape)\n",
    "print ('image_ids_test shape:', image_ids_test.shape)\n",
    "\n",
    "print ('classes_train shape:', classes_train.shape)\n",
    "print ('classes_val shape:', classes_val.shape)\n",
    "print ('classes_test shape:', classes_test.shape)\n",
    "\n",
    "# check the stratification\n",
    "\n",
    "classes_train_perc = []\n",
    "classes_val_perc = []\n",
    "classes_test_perc = []\n",
    "\n",
    "for i in range(0, len(classes_list)):\n",
    "    classes_train_perc_i = classes_train.value_counts()[i] / len(classes_train)\n",
    "    classes_train_perc.append(classes_train_perc_i)\n",
    "    \n",
    "    classes_val_perc_i = classes_val.value_counts()[i] / len(classes_val)\n",
    "    classes_val_perc.append(classes_val_perc_i)\n",
    "    \n",
    "    classes_test_perc_i = classes_test.value_counts()[i] / len(classes_test)\n",
    "    classes_test_perc.append(classes_test_perc_i)\n",
    "\n",
    "print('The distribution of classes in the training set:', \"{0:.2f}%\".format(classes_train_perc[0] * 100),',',\n",
    "                                                          \"{0:.2f}%\".format(classes_train_perc[1] * 100),',',\n",
    "                                                          \"{0:.2f}%\".format(classes_train_perc[2] * 100),',',\n",
    "                                                          \"{0:.2f}%\".format(classes_train_perc[3] * 100),',',\n",
    "                                                          \"{0:.2f}%\".format(classes_train_perc[4] * 100),',',\n",
    "                                                          \"{0:.2f}%\".format(classes_train_perc[5] * 100),',',\n",
    "                                                          \"{0:.2f}%\".format(classes_train_perc[6] * 100),',',\n",
    "                                                          \"{0:.2f}%\".format(classes_train_perc[7] * 100),',',\n",
    "                                                          \"{0:.2f}%\".format(classes_train_perc[8] * 100))\n",
    "\n",
    "print('The distribution of classes in the validation set:', \"{0:.2f}%\".format(classes_val_perc[0] * 100),',',\n",
    "                                                            \"{0:.2f}%\".format(classes_val_perc[1] * 100),',',\n",
    "                                                            \"{0:.2f}%\".format(classes_val_perc[2] * 100),',',\n",
    "                                                            \"{0:.2f}%\".format(classes_val_perc[3] * 100),',',\n",
    "                                                            \"{0:.2f}%\".format(classes_val_perc[4] * 100),',',\n",
    "                                                            \"{0:.2f}%\".format(classes_val_perc[5] * 100),',',\n",
    "                                                            \"{0:.2f}%\".format(classes_val_perc[6] * 100),',',\n",
    "                                                            \"{0:.2f}%\".format(classes_val_perc[7] * 100),',',\n",
    "                                                            \"{0:.2f}%\".format(classes_val_perc[8] * 100))\n",
    "\n",
    "print('The distribution of classes in the test set:', \"{0:.2f}%\".format(classes_test_perc[0] * 100),',',\n",
    "                                                      \"{0:.2f}%\".format(classes_test_perc[1] * 100),',',\n",
    "                                                      \"{0:.2f}%\".format(classes_test_perc[2] * 100),',',\n",
    "                                                      \"{0:.2f}%\".format(classes_test_perc[3] * 100),',',\n",
    "                                                      \"{0:.2f}%\".format(classes_test_perc[4] * 100),',',\n",
    "                                                      \"{0:.2f}%\".format(classes_test_perc[5] * 100),',',\n",
    "                                                      \"{0:.2f}%\".format(classes_test_perc[6] * 100),',',\n",
    "                                                      \"{0:.2f}%\".format(classes_test_perc[7] * 100),',',\n",
    "                                                      \"{0:.2f}%\".format(classes_test_perc[8] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# due to the low number of images in the category 'Food' these images will be added to the category 'Other'\n",
    "classes_list_new = list(classes_list)\n",
    "classes_list_new[1] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the training data\n",
    "\n",
    "for i in range(0, len(filenames_train)):\n",
    "\n",
    "    destination = 'image_classifier/training_data/' + classes_list_new[classes_train.iloc[i,]]\n",
    "    \n",
    "    # create the folder bases on folder_path\n",
    "    if not os.path.exists(destination):\n",
    "        os.makedirs(destination)\n",
    "    \n",
    "    # copy the picture if it exists\n",
    "    if os.path.isfile('image_classifier/' + classes_list[classes_train.iloc[i,]] + '/' + filenames_train.iloc[i,]):\n",
    "        copy('image_classifier/' + classes_list[classes_train.iloc[i,]] + '/' + filenames_train.iloc[i,], destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the validation data\n",
    "\n",
    "for i in range(0, len(filenames_val)):\n",
    "\n",
    "    destination = 'image_classifier/validation_data/' + classes_list_new[classes_val.iloc[i,]]\n",
    "    \n",
    "    # create the folder bases on folder_path\n",
    "    if not os.path.exists(destination):\n",
    "        os.makedirs(destination)\n",
    "    \n",
    "    # copy the picture if it exists\n",
    "    if os.path.isfile('image_classifier/' + classes_list[classes_val.iloc[i,]] + '/' + filenames_val.iloc[i,]):\n",
    "        copy('image_classifier/' + classes_list[classes_val.iloc[i,]] + '/' + filenames_val.iloc[i,], destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the test data\n",
    "\n",
    "for i in range(0, len(filenames_test)):\n",
    "\n",
    "    destination = 'image_classifier/test_data/' + classes_list_new[classes_test.iloc[i,]]\n",
    "    \n",
    "    # create the folder bases on folder_path\n",
    "    if not os.path.exists(destination):\n",
    "        os.makedirs(destination)\n",
    "    \n",
    "    # copy the picture if it exists\n",
    "    if os.path.isfile('image_classifier/' + classes_list[classes_test.iloc[i,]] + '/' + filenames_test.iloc[i,]):\n",
    "        copy('image_classifier/' + classes_list[classes_test.iloc[i,]] + '/' + filenames_test.iloc[i,], destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = []\n",
    "\n",
    "for i in range(0, len(classes_list_new)):\n",
    "    weights_temp = []\n",
    "    weights_temp = [classes_list_new[i], classes_train.value_counts()[i]]\n",
    "    weights.append(weights_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_aggregated = []\n",
    "\n",
    "for key, group in itertools.groupby(sorted(weights), operator.itemgetter(0)):\n",
    "    s = sum(int(t[1]) for t in group)\n",
    "    \n",
    "    weights_aggregated.append([key, s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_aggregated_df = pd.DataFrame(weights_aggregated)\n",
    "weights_aggregated_df.columns = ['Category', 'Number_samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_aggregated_df.to_csv('results/class_weights.csv', sep = ',', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
