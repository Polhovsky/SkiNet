{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "account_data_01 = pd.read_csv('results/dataset_analysis.csv', low_memory = False)\n",
    "clusters = pd.read_csv('results/clusters.csv', low_memory = False)\n",
    "account_data_02 = account_data_01.merge(clusters, on = 'image_id', how = 'inner')\n",
    "\n",
    "print('Number of samples in account_data_01:', account_data_01.shape[0])\n",
    "print('Number of samples in account_data_02:', account_data_02.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's create a feature matrix, a cluster vector and a target variable\n",
    "X = account_data_02.drop(['likes_groups', 'log_likes_image_corrected', 'likes_image_corrected', 'cluster', 'image_id', 'resort', 'accountname'], axis = 1)\n",
    "clusters = account_data_02['cluster']\n",
    "image_ids = account_data_02['image_id']\n",
    "Y = account_data_02['likes_groups'].apply(lambda x: int(str(x)[0]))\n",
    "\n",
    "stratification = pd.concat([Y, clusters], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, stratification.shape, Y.shape, stratification.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training-, validation and test set\n",
    "\n",
    "X_temp, X_test, \\\n",
    "Y_temp, Y_test, \\\n",
    "image_ids_temp, image_ids_test, \\\n",
    "stratification_temp, stratification_test = train_test_split(X,\n",
    "                                                            Y,\n",
    "                                                            image_ids,\n",
    "                                                            stratification,\n",
    "                                                            stratify = stratification,\n",
    "                                                            test_size = 0.2,\n",
    "                                                            train_size = 0.8,\n",
    "                                                            random_state = 0)\n",
    "\n",
    "X_train, X_val, \\\n",
    "Y_train, Y_val, \\\n",
    "image_ids_train, image_ids_val, \\\n",
    "stratification_train, stratification_val = train_test_split(X_temp,\n",
    "                                                            Y_temp,\n",
    "                                                            image_ids_temp,\n",
    "                                                            stratification_temp,\n",
    "                                                            stratify = stratification_temp,\n",
    "                                                            test_size = 0.25,\n",
    "                                                            train_size = 0.75,\n",
    "                                                            random_state = 0)\n",
    "\n",
    "# print the number of examples in and dimensions of each set\n",
    "\n",
    "print ('Number of training examples:', X_train.shape[0])\n",
    "print ('Number of validation examples:', X_val.shape[0])\n",
    "print ('Number of test examples:', X_test.shape[0])\n",
    "\n",
    "print ('X_train shape:', X_train.shape)\n",
    "print ('X_valshape:', X_val.shape)\n",
    "print ('X_test shape:', X_test.shape)\n",
    "\n",
    "print ('Y_train shape:', Y_train.shape)\n",
    "print ('Y_val shape:', Y_val.shape)\n",
    "print ('Y_test shape:', Y_test.shape)\n",
    "\n",
    "# check the stratification\n",
    "\n",
    "clusters_training_perc = stratification_train['cluster'].sum() / stratification_train.shape[0]\n",
    "clusters_validation_perc = stratification_val['cluster'].sum() / stratification_val.shape[0]\n",
    "clusters_test_perc = stratification_test['cluster'].sum() / stratification_test.shape[0]\n",
    "\n",
    "print('The percentage of cluster 1 in the training set:', \"{0:.2f}%\".format(clusters_training_perc * 100))\n",
    "print('The percentage of cluster 1 in the validation set:', \"{0:.2f}%\".format(clusters_validation_perc * 100))\n",
    "print('The percentage of cluster 1 in the test set:', \"{0:.2f}%\".format(clusters_test_perc * 100))\n",
    "\n",
    "print('The distribution of the labels in the training set:', \"{0:.2f}%\".format(Y_train[Y_train == 1].count() / Y_train.shape[0] * 100),',',\n",
    "                                                             \"{0:.2f}%\".format(Y_train[Y_train == 2].count() / Y_train.shape[0] * 100),',',\n",
    "                                                             \"{0:.2f}%\".format(Y_train[Y_train == 3].count() / Y_train.shape[0] * 100),',',\n",
    "                                                             \"{0:.2f}%\".format(Y_train[Y_train == 4].count() / Y_train.shape[0] * 100),',',\n",
    "                                                             \"{0:.2f}%\".format(Y_train[Y_train == 5].count() / Y_train.shape[0] * 100))\n",
    "\n",
    "print('The distribution of the labels in the validation set:', \"{0:.2f}%\".format(Y_val[Y_val == 1].count() / Y_val.shape[0] * 100),',',\n",
    "                                                               \"{0:.2f}%\".format(Y_val[Y_val == 2].count() / Y_val.shape[0] * 100),',',\n",
    "                                                               \"{0:.2f}%\".format(Y_val[Y_val == 3].count() / Y_val.shape[0] * 100),',',\n",
    "                                                               \"{0:.2f}%\".format(Y_val[Y_val == 4].count() / Y_val.shape[0] * 100),',',\n",
    "                                                               \"{0:.2f}%\".format(Y_val[Y_val == 5].count() / Y_val.shape[0] * 100))\n",
    "\n",
    "print('The distribution of the labels in the test set:', \"{0:.2f}%\".format(Y_test[Y_test == 1].count() / Y_test.shape[0] * 100),',',\n",
    "                                                         \"{0:.2f}%\".format(Y_test[Y_test == 2].count() / Y_test.shape[0] * 100),',',\n",
    "                                                         \"{0:.2f}%\".format(Y_test[Y_test == 3].count() / Y_test.shape[0] * 100),',',\n",
    "                                                         \"{0:.2f}%\".format(Y_test[Y_test == 4].count() / Y_test.shape[0] * 100),',',\n",
    "                                                         \"{0:.2f}%\".format(Y_test[Y_test == 5].count() / Y_test.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write the image_ids in the training, validation and test set to file\n",
    "image_ids_train.to_frame().reset_index().drop('index', axis = 1).to_csv('results/image_ids_train.csv', sep = ',', index = False)\n",
    "image_ids_val.to_frame().reset_index().drop('index', axis = 1).to_csv('results/image_ids_val.csv', sep = ',', index = False)\n",
    "image_ids_test.to_frame().reset_index().drop('index', axis = 1).to_csv('results/image_ids_test.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "# let's check the importance of the features and select only the relevant ones\n",
    "\n",
    "clf = ExtraTreesClassifier(random_state = 0).fit(X_train, Y_train)\n",
    "\n",
    "features = []\n",
    "\n",
    "for feature, importance in zip(X_train.columns, clf.feature_importances_):\n",
    "    features.append((importance, feature))\n",
    "\n",
    "features.sort(reverse = True)\n",
    "features_relevant = [x[1] for x in features if x[0] > 0.001]\n",
    "\n",
    "features = pd.DataFrame()\n",
    "\n",
    "features['feature'] = X_train.columns\n",
    "features['importance'] = clf.feature_importances_\n",
    "\n",
    "features.sort_values(by = ['importance'], ascending = True, inplace = True)\n",
    "\n",
    "# select the 15 most important features for visualization purposes\n",
    "features = features.iloc[-15:, :]\n",
    "\n",
    "features.set_index('feature', inplace = True)\n",
    "features.plot(kind = 'barh',\n",
    "              figsize = (10, 12),\n",
    "              color = \"#FF9933\",\n",
    "              ec = \"black\",\n",
    "              linewidth = 0.5,\n",
    "              legend = None)\n",
    "\n",
    "plt.title('\\nWhich features are important?\\n', fontsize = 14)\n",
    "plt.xlabel('Importance', fontsize = 11,  labelpad = 10)\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{0:.3f}\".format\n",
    "print(features.sort_values('importance', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's scale the data (mean of zero and standard deviation of one) as input to a logistic regression for\n",
    "# maximum interpretability of the results and perform a sanity check to see whether each feature has in fact\n",
    "# a mean of zero and standard deviation one\n",
    "\n",
    "X_train_selection = X_train[features_relevant]\n",
    "X_val_selection = X_val[features_relevant]\n",
    "X_test_selection = X_test[features_relevant]\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_selection)\n",
    "\n",
    "X_train_selection_scaled = scaler.transform(X_train_selection)\n",
    "X_val_selection_scaled = scaler.transform(X_val_selection)\n",
    "X_test_selection_scaled = scaler.transform(X_test_selection)\n",
    "\n",
    "print('Information about the training set:\\n')\n",
    "print('   - datatype:', X_train_selection_scaled.dtype)\n",
    "print('   - shape of the dataset:', X_train_selection_scaled.shape)\n",
    "print('   - sum of the means of the columns:', round(X_train_selection_scaled.mean(axis = 0).sum(), 2))\n",
    "print('   - sum of the standard deviations of the columns:', round(X_train_selection_scaled.std(axis = 0).sum(), 2))\n",
    "print('\\n')\n",
    "print('Information about the validation set:\\n')\n",
    "print('   - datatype:', X_val_selection_scaled.dtype)\n",
    "print('   - shape of the dataset:', X_val_selection_scaled.shape)\n",
    "print('   - sum of the means of the columns:', round(X_val_selection_scaled.mean(axis = 0).sum(), 2))\n",
    "print('   - sum of the standard deviations of the columns:', round(X_val_selection_scaled.std(axis = 0).sum(), 2))\n",
    "print('\\n')\n",
    "print('Information about the test set:\\n')\n",
    "print('   - datatype:', X_test_selection_scaled.dtype)\n",
    "print('   - shape of the dataset:', X_test_selection_scaled.shape)\n",
    "print('   - sum of the means of the columns:', round(X_test_selection_scaled.mean(axis = 0).sum(), 2))\n",
    "print('   - sum of the standard deviations of the columns:', round(X_test_selection_scaled.std(axis = 0).sum(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a logistic regression classifier and output the accuracy for both the training and validation set\n",
    "\n",
    "clf = LogisticRegression(multi_class = 'multinomial', solver = 'newton-cg', random_state = 0).fit(X_train_selection_scaled, Y_train)\n",
    "\n",
    "# accuracy for the training set\n",
    "Y_train_pred = clf.predict(X_train_selection_scaled)\n",
    "accuracy_train = accuracy_score(Y_train, Y_train_pred)\n",
    "\n",
    "# accuracy for the validation set\n",
    "Y_val_pred = clf.predict(X_val_selection_scaled)\n",
    "accuracy_validation = accuracy_score(Y_val, Y_val_pred)\n",
    "\n",
    "print('Accuracy on the training set:', \"{0:.2f}\".format(accuracy_train))\n",
    "print('Accuracy on the validation set:', \"{0:.2f}\".format(accuracy_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check for multicollinearity\n",
    "\n",
    "c = X_train_selection.corr().abs()\n",
    "c *= np.tri(*c.shape)\n",
    "\n",
    "s = c.unstack()\n",
    "\n",
    "so = s.sort_values(kind = 'quicksort', ascending = False)\n",
    "so = so[so < 1]\n",
    "so.nlargest(50)\n",
    "\n",
    "# remove the following features due to high correlation with other features:\n",
    "# - male_18_29_state\n",
    "# - female_18_29_state\n",
    "# - state_California\n",
    "# - temp_min_celsius_1 t/m temp_min_celsius_12\n",
    "# - temp_max_celsius_1 t/m temp_min_celsius_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_multicollinearity = ['male_18_29_state',\n",
    "                              'female_18_29_state',\n",
    "                              'ranking_overall',\n",
    "                              'temp_max_celsius_min1',\n",
    "                              'temp_max_celsius_plus1',\n",
    "                              'temp_min_celsius_min1',\n",
    "                              'temp_min_celsius_plus1',              \n",
    "                              'precipitation_mm_min1',\n",
    "                              'precipitation_mm_min0',\n",
    "                              'precipitation_mm_plus1',\n",
    "                              'average_yearly_snowfall',\n",
    "                              'state_California',\n",
    "                              'state_Wyoming',\n",
    "                              \n",
    "                              'temp_min_celsius_1',\n",
    "                              'temp_min_celsius_2',\n",
    "                              'temp_min_celsius_3',\n",
    "                              'temp_min_celsius_4',\n",
    "                              'temp_min_celsius_5',\n",
    "                              'temp_min_celsius_6',\n",
    "                              'temp_min_celsius_7',\n",
    "                              'temp_min_celsius_8',\n",
    "                              'temp_min_celsius_9',\n",
    "                              'temp_min_celsius_10',\n",
    "                              'temp_min_celsius_11',\n",
    "                              'temp_min_celsius_12',\n",
    "                                 \n",
    "                              'temp_max_celsius_1',\n",
    "                              'temp_max_celsius_2',\n",
    "                              'temp_max_celsius_3',\n",
    "                              'temp_max_celsius_4',\n",
    "                              'temp_max_celsius_5',\n",
    "                              'temp_max_celsius_6',\n",
    "                              'temp_max_celsius_7',\n",
    "                              'temp_max_celsius_8',\n",
    "                              'temp_max_celsius_9',\n",
    "                              'temp_max_celsius_10',\n",
    "                              'temp_max_celsius_11',\n",
    "                              'temp_max_celsius_12',\n",
    "                             \n",
    "                              'precipitation_mm_1',\n",
    "                              'precipitation_mm_2',\n",
    "                              'precipitation_mm_3',\n",
    "                              'precipitation_mm_4',\n",
    "                              'precipitation_mm_5',\n",
    "                              'precipitation_mm_6',\n",
    "                              'precipitation_mm_7',\n",
    "                              'precipitation_mm_8',\n",
    "                              'precipitation_mm_9',\n",
    "                              'precipitation_mm_10',\n",
    "                              'precipitation_mm_11',\n",
    "                              'precipitation_mm_12']\n",
    "\n",
    "features_relevant_update = [x for x in features_relevant if x not in features_multicollinearity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_relevant), len(features_multicollinearity), len(features_relevant_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the relevant features\n",
    "\n",
    "features_df = pd.DataFrame(features_relevant_update)\n",
    "features_df.rename(columns = {0: 'feature'}, inplace = True)\n",
    "features_df.to_csv('results/features_relevant_logistic_regression.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's scale the data (mean of zero and standard deviation of one) as input to a logistic regression for\n",
    "# maximum interpretability of the results and perform a sanity check to see whether each feature has in fact\n",
    "# a mean of zero and standard deviation one\n",
    "\n",
    "X_train_selection = X_train[features_relevant_update]\n",
    "X_val_selection = X_val[features_relevant_update]\n",
    "X_test_selection = X_test[features_relevant_update]\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_selection)\n",
    "\n",
    "X_train_selection_scaled = scaler.transform(X_train_selection)\n",
    "X_val_selection_scaled = scaler.transform(X_val_selection)\n",
    "X_test_selection_scaled = scaler.transform(X_test_selection)\n",
    "\n",
    "print('Information about the training set:\\n')\n",
    "print('   - datatype:', X_train_selection_scaled.dtype)\n",
    "print('   - shape of the dataset:', X_train_selection_scaled.shape)\n",
    "print('   - sum of the means of the columns:', round(X_train_selection_scaled.mean(axis = 0).sum(), 2))\n",
    "print('   - sum of the standard deviations of the columns:', round(X_train_selection_scaled.std(axis = 0).sum(), 2))\n",
    "print('\\n')\n",
    "print('Information about the validation set:\\n')\n",
    "print('   - datatype:', X_val_selection_scaled.dtype)\n",
    "print('   - shape of the dataset:', X_val_selection_scaled.shape)\n",
    "print('   - sum of the means of the columns:', round(X_val_selection_scaled.mean(axis = 0).sum(), 2))\n",
    "print('   - sum of the standard deviations of the columns:', round(X_val_selection_scaled.std(axis = 0).sum(), 2))\n",
    "print('\\n')\n",
    "print('Information about the test set:\\n')\n",
    "print('   - datatype:', X_test_selection_scaled.dtype)\n",
    "print('   - shape of the dataset:', X_test_selection_scaled.shape)\n",
    "print('   - sum of the means of the columns:', round(X_test_selection_scaled.mean(axis = 0).sum(), 2))\n",
    "print('   - sum of the standard deviations of the columns:', round(X_test_selection_scaled.std(axis = 0).sum(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "# let's check the importance of the features and select only the relevant ones\n",
    "\n",
    "clf = ExtraTreesClassifier(random_state = 0).fit(X_train[features_relevant_update], Y_train)\n",
    "\n",
    "features = []\n",
    "\n",
    "for feature, importance in zip(X_train[features_relevant_update].columns, clf.feature_importances_):\n",
    "    features.append((importance, feature))\n",
    "\n",
    "features.sort(reverse = True)\n",
    "features_relevant = [x[1] for x in features if x[0] > 0.001]\n",
    "\n",
    "features = pd.DataFrame()\n",
    "\n",
    "features['feature'] = X_train[features_relevant_update].columns\n",
    "features['importance'] = clf.feature_importances_\n",
    "\n",
    "features.sort_values(by = ['importance'], ascending = True, inplace = True)\n",
    "\n",
    "# select the 15 most important features for visualization purposes\n",
    "features = features.iloc[-15:, :]\n",
    "\n",
    "features.set_index('feature', inplace = True)\n",
    "features.plot(kind = 'barh',\n",
    "              figsize = (10, 12),\n",
    "              color = \"#FF9933\",\n",
    "              ec = \"black\",\n",
    "              linewidth = 0.5,\n",
    "              legend = None)\n",
    "\n",
    "plt.title('\\nWhich features are important?\\n', fontsize = 14)\n",
    "plt.xlabel('Importance', fontsize = 11,  labelpad = 10)\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a logistic regression classifier and output the accuracy for both the training and validation set\n",
    "\n",
    "clf = LogisticRegression(multi_class = 'multinomial', solver = 'newton-cg', random_state = 0).fit(X_train_selection_scaled, Y_train)\n",
    "\n",
    "# accuracy for the training set\n",
    "Y_train_pred = clf.predict(X_train_selection_scaled)\n",
    "accuracy_train = accuracy_score(Y_train, Y_train_pred)\n",
    "\n",
    "# accuracy for the validation set\n",
    "Y_val_pred = clf.predict(X_val_selection_scaled)\n",
    "accuracy_validation = accuracy_score(Y_val, Y_val_pred)\n",
    "\n",
    "print('Accuracy on the training set:', \"{0:.2f}\".format(accuracy_train))\n",
    "print('Accuracy on the validation set:', \"{0:.2f}\".format(accuracy_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy for the test set\n",
    "Y_test_pred = clf.predict(X_test_selection_scaled)\n",
    "accuracy_test = accuracy_score(Y_test, Y_test_pred)\n",
    "\n",
    "print('Accuracy on the test set:', \"{0:.2f}\".format(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame(np.column_stack((X_train_selection.columns.values, clf.coef_.T)))\n",
    "coefficients.columns = ['feature', '1 - HH', '2 - H', '3 - M', '4 - L', '5 - LL']\n",
    "coefficients.to_csv('results/LR_baseline_weights.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(clf.intercept_).to_csv('results/LR_baseline_intercept.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X_test_selection_scaled).to_csv('results/LR_baseline_X_test.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's construct the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(Y_test, Y_test_pred, labels = None, sample_weight = None)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's add the predictions to the features to analyse a bit more\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for image_id, pred in zip(image_ids_test, Y_test_pred):\n",
    "    predictions.append((image_id, pred))\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.columns = ['image_id', 'prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the other features and select the relevant ones for this purpose\n",
    "predictions_df = account_data_02.merge(predictions_df, on = 'image_id', how = 'inner')\n",
    "predictions_df = predictions_df[['image_id', 'resort', 'cluster', 'likes_groups', 'prediction']]\n",
    "predictions_df['likes_groups'] = predictions_df['likes_groups'].apply(lambda x: int(str(x)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an overview of the predictions versus the original categories per resort\n",
    "overview = predictions_df.groupby(['resort', 'likes_groups', 'prediction']).image_id.count().reset_index().rename(columns = {'image_id': 'count'})\n",
    "overview['correct'] = np.where(overview['prediction'] == overview['likes_groups'], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_per_group = overview[['resort', 'correct', 'count']].groupby(['resort', 'correct']).sum().reset_index().rename(columns = {'count': 'count_per_group'})\n",
    "sum_total = overview[['resort', 'count']].groupby(['resort']).sum().reset_index().rename(columns = {'count': 'total'})\n",
    "percentage = sum_per_group.merge(sum_total, on = 'resort', how = 'outer')\n",
    "percentage['percentage'] = 100 * percentage['count_per_group'] / percentage['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_top10 = percentage[(percentage['total'] >= 100) & (percentage['correct'] == 1)].nlargest(10, 'percentage') \\\n",
    "                    .sort_values(by = 'percentage', ascending = False).set_index('resort')\n",
    "percentage_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_worst10 = percentage[percentage['correct'] == 1].nsmallest(10, 'percentage') \\\n",
    "                        .sort_values(by = 'percentage', ascending = False).set_index('resort')\n",
    "percentage_worst10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save files so they can be used in graph of final model\n",
    "percentage_top10.to_csv('results/LR_baseline_top10.csv', sep = ',', index = False)\n",
    "percentage_worst10.to_csv('results/LR_baseline_worst10.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top10_resorts = percentage_top10.index.values.tolist()\n",
    "worst10_resorts = percentage_worst10.index.values.tolist()\n",
    "xticks_labels = [None] * (len(top10_resorts) + len(worst10_resorts))\n",
    "xticks_labels[::2] = top10_resorts\n",
    "xticks_labels[1::2] = worst10_resorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "fig = plt.figure(figsize = (12, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "index = np.linspace(0, 19, 10)\n",
    "bar_width = 0.6\n",
    "\n",
    "top10 = plt.bar(index,\n",
    "                percentage_top10['percentage'],\n",
    "                bar_width,\n",
    "                color = '#0099FF',\n",
    "                ec = 'black',\n",
    "                linewidth = 0.5)\n",
    "\n",
    "X = np.linspace(0, 19, 10)\n",
    "Y = np.array(percentage_top10['percentage'])\n",
    "Z1 = np.array(percentage_top10['count_per_group'])\n",
    "Z2 = np.array(percentage_top10['total'])\n",
    "\n",
    "for a, b, c, d in zip(X, Y, Z1, Z2): \n",
    "    plt.text(a + 0.05, b + 3, '[' + str(c) + ' / ' + str(d) + ']', fontsize = 8, ha = 'center', va = 'center')\n",
    "    \n",
    "worst10 = plt.bar(index + 1,\n",
    "                  percentage_worst10['percentage'],\n",
    "                  bar_width,\n",
    "                  color = '#FF9933',\n",
    "                  ec = 'black',\n",
    "                  linewidth = 0.5)\n",
    "\n",
    "X = np.linspace(1, 20, 10)\n",
    "Y = np.array(percentage_worst10['percentage'])\n",
    "Z1 = np.array(percentage_worst10['count_per_group'])\n",
    "Z2 = np.array(percentage_worst10['total'])\n",
    "\n",
    "for a, b, c, d in zip(X, Y, Z1, Z2): \n",
    "    plt.text(a + 0.05, b + 3, '[' + str(c) + ' / ' + str(d) + ']', fontsize = 8, ha = 'center', va = 'center')\n",
    "\n",
    "xticks_major = xticks_major = np.linspace(0, 20, 20)\n",
    "ax.set_xticks(xticks_major)\n",
    "ax.set_xticklabels(xticks_labels, fontsize = 10, rotation = 'vertical')\n",
    "\n",
    "plt.ylim(0, 110)\n",
    "yticks_major = np.round(np.linspace(0, 100, 11), 10)\n",
    "yticks_major_str = (yticks_major).astype(int).astype(str).tolist()\n",
    "yticks_labels = [x + ' %' for x in yticks_major_str]\n",
    "ax.set_yticks(yticks_major)\n",
    "ax.set_yticklabels(yticks_labels, fontsize = 10)\n",
    "ax.yaxis.grid(color = '#333333', alpha = 0.25, zorder = 1)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "legend = plt.legend([top10, worst10],\n",
    "                ['ten resorts with the highest accuracy',\n",
    "                'ten resorts with the lowest accuracy'],\n",
    "                fontsize = 8,\n",
    "                loc = 1,\n",
    "                facecolor = 'white',\n",
    "                edgecolor = 'black',\n",
    "                borderaxespad = 1)\n",
    "\n",
    "plt.suptitle('The ten resorts with the highest / lowest accuracy', fontsize = 14, y = 0.97)\n",
    "plt.title('(number of correct predictions versus number of samples in the test set in brackets)', fontsize = 10, y = 1.02)\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Accuracy', fontsize = 11)\n",
    "plt.show()\n",
    "\n",
    "filename = 'results/top10_worst10_baseline.png'\n",
    "fig.savefig(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
