{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import urllib.parse\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "# the following features will be in the picture specific dataset:\n",
    "#    - number of likes\n",
    "#    - date of posting\n",
    "#    - date of scraping\n",
    "#    - 'age' of the picture in days (how many days the picture has been online)\n",
    "#    - month in which the picture has been posted\n",
    "#    - quarter in which the picture has been posted\n",
    "#    - time of the post (hour of the day ranging from 0 to 23)\n",
    "#    - number of hash tags extracted from the post, not from the comments\n",
    "#    - number of comments (possible cannot be used due to data leakage, explain ...)\n",
    "#    - weather stats (precipitation, minimum temperature and maximum temperature of a day) around the date of posting\n",
    "\n",
    "# stats_table contains the following features:\n",
    "#    - name of resort\n",
    "#    - state in order to merge the weather data\n",
    "#    - latitude and longitude in order to calculate distance to weather station\n",
    "\n",
    "# resorts_elevation contains the following features:\n",
    "#    - name of the resort\n",
    "#    - minimum and maximum elevation of the resort\n",
    "\n",
    "# resorts_time_zone contains the following features:\n",
    "#    - name of the resort\n",
    "#    - time difference compared to UTC of the resort\n",
    "\n",
    "account_01 = pd.read_csv('results/stats_table.csv', sep = ',', encoding = \"ISO-8859-1\")\n",
    "\n",
    "elevation = pd.read_csv('other_data/resorts_elevation.csv', sep = ',', encoding = \"ISO-8859-1\")\n",
    "elevation = elevation[['resort', 'min elevation (m)', 'max elevation (m)']]\n",
    "elevation.rename(columns = {'min elevation (m)': 'minimum_elevation',\n",
    "                            'max elevation (m)': 'maximum_elevation'}, inplace = True)\n",
    "\n",
    "time_zone = pd.read_csv('other_data/resorts_time_zone.csv', sep = ',', encoding = \"ISO-8859-1\")\n",
    "\n",
    "account_02 = account_01.merge(elevation, on = 'resort', how = 'inner')\n",
    "account_03 = account_02.merge(time_zone, on = 'resort', how = 'inner')\n",
    "\n",
    "account_03.drop(['followers', 'number_useful_pictures', 'number_images_trash', 'number_images_total', 'zip_code'], axis = 1, inplace = True)\n",
    "\n",
    "print('The number of resorts in account_01 is:', account_01.resort.count())\n",
    "print('The number of resorts in account_02 is:', account_02.resort.count())\n",
    "print('The number of resorts in account_03 is:', account_03.resort.count())\n",
    "\n",
    "# accountname, resort, state, longitude, latitude, minimum_elevation, maximum_elevation, time_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_04 = account_03.values.tolist()\n",
    "\n",
    "# for some resorts snow- & snow water equivalent data and data regarding weather types were available but not for all,\n",
    "# so I decided to only use precipitation, maximum and minimum temperature since they were available (with decent coverage)\n",
    "# for all resorts\n",
    "\n",
    "df_01 = pd.DataFrame()\n",
    "account_stats_total = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(account_04)):\n",
    "    \n",
    "    print('Resort:', account_04[i][1])\n",
    "    \n",
    "    # set the URL to the Instagram account\n",
    "    url = 'https://www.instagram.com/' + str(account_04[i][0])\n",
    "\n",
    "    # folder of the data\n",
    "    path = urllib.parse.urlparse(url).path\n",
    "    folder_name = path.replace('/', '')\n",
    "    folder_path = 'images/{}/'.format(folder_name)\n",
    "\n",
    "    account_data = pd.read_csv(os.path.join(folder_path, str(account_04[i][0]) + '_stats.csv'), sep = ',', encoding = \"ISO-8859-1\")\n",
    "    image_list_01 = account_data.values.tolist()\n",
    "    \n",
    "    image_list_02 = []\n",
    "\n",
    "    for j in range(len(image_list_01)):\n",
    "        if os.path.isfile(folder_path + str(image_list_01[j][1]) + str('.jpg')):\n",
    "            picture_stats = image_list_01[j] + [account_04[i][1]]\n",
    "            image_list_02.append(picture_stats)\n",
    "\n",
    "    df_temp = pd.DataFrame(image_list_02, columns = list(account_data.columns) + ['resort'])\n",
    "\n",
    "    df_temp['likes_image'] = df_temp['likes_image'].astype('int64')\n",
    "    df_temp['comments_image'] = df_temp['comments_image'].astype('int64')\n",
    "    \n",
    "    df_temp['date_post_min0'] = pd.to_datetime(df_temp['date_post'])\n",
    "    df_temp['date_scrape'] = pd.to_datetime(df_temp['date_scrape'])\n",
    "    df_temp['days_online'] = df_temp['date_scrape'] - df_temp['date_post_min0']\n",
    "    df_temp['days_online'] = df_temp['days_online'].astype('timedelta64[D]').astype('int64')\n",
    "    \n",
    "    # add information from the overall table\n",
    "    df_temp['latitude'] = account_04[i][4]\n",
    "    df_temp['longitude'] = account_04[i][3]\n",
    "    df_temp['time_difference'] = account_04[i][7]\n",
    "    \n",
    "    # extract the time and the time zone from the time_post\n",
    "    df_temp['time'] = df_temp['time_post'].apply(lambda x: re.search('.+?(?=am|pm)', str(x)).group(0)) # anything before am / pm\n",
    "    df_temp['am_pm'] = df_temp['time_post'].apply(lambda x: re.search('(?=:)(.*)', str(x)).group(0)[3:5]) # am or pm\n",
    "    df_temp['time_zone'] = df_temp['time_post'].apply(lambda x: re.search('[^am|pm]*$', str(x)).group(0).strip()) # anything after am / pm\n",
    "\n",
    "    df_temp['hour_am_pm_UTC'] = df_temp['time'].apply(lambda x: re.search('.+?(?=:)', str(x)).group(0)).astype('int64') # anything before :\n",
    "    \n",
    "    # convert am/pm to 24 hour clock time\n",
    "    \n",
    "    # - 12 am -> 0\n",
    "    # - 1 - 11 am -> 1 - 11\n",
    "    # - 12 pm -> 12\n",
    "    # - 1 - 11 pm -> 13 - 23\n",
    "    \n",
    "    for index, row in df_temp.iterrows():\n",
    "        if row['am_pm'] == 'am':\n",
    "            if row['hour_am_pm_UTC'] == 12:\n",
    "                df_temp.loc[index, 'hour_24_UTC'] = 0\n",
    "            else:\n",
    "                df_temp.loc[index, 'hour_24_UTC'] = df_temp.loc[index, 'hour_am_pm_UTC']\n",
    "        else:\n",
    "            if row['hour_am_pm_UTC'] == 12:\n",
    "                df_temp.loc[index, 'hour_24_UTC'] = 12\n",
    "            else:\n",
    "                df_temp.loc[index, 'hour_24_UTC'] = df_temp.loc[index, 'hour_am_pm_UTC'] + 12\n",
    "    \n",
    "    df_temp['hour_24_UTC'] = df_temp['hour_24_UTC'].astype('int64')\n",
    "    \n",
    "    # apply the time difference to convert the time from UTC to local time while taking daylight saving time into account\n",
    "    \n",
    "    for index, row in df_temp.iterrows():\n",
    "        if row['time_zone'] == 'UTC':\n",
    "            df_temp.loc[index, 'hour_24_local'] = df_temp.loc[index, 'hour_24_UTC'] + df_temp.loc[index, 'time_difference']\n",
    "            \n",
    "            # correct for daylight saving time (time difference is one hour more from first Sunday in November till\n",
    "            # second Sunday in March)\n",
    "            if (((row['date_post_min0'].date() >= datetime.date(2009, 11, 1)) & (row['date_post_min0'].date() < datetime.date(2010, 3, 14))) |\n",
    "                ((row['date_post_min0'].date() >= datetime.date(2010, 11, 7)) & (row['date_post_min0'].date() < datetime.date(2011, 3, 13))) |\n",
    "                ((row['date_post_min0'].date() >= datetime.date(2011, 11, 6)) & (row['date_post_min0'].date() < datetime.date(2012, 3, 11))) |\n",
    "                ((row['date_post_min0'].date() >= datetime.date(2102, 11, 4)) & (row['date_post_min0'].date() < datetime.date(2013, 3, 10))) |\n",
    "                ((row['date_post_min0'].date() >= datetime.date(2013, 11, 3)) & (row['date_post_min0'].date() < datetime.date(2014, 3,  9))) |\n",
    "                ((row['date_post_min0'].date() >= datetime.date(2014, 11, 2)) & (row['date_post_min0'].date() < datetime.date(2015, 3,  8))) |\n",
    "                ((row['date_post_min0'].date() >= datetime.date(2015, 11, 1)) & (row['date_post_min0'].date() < datetime.date(2016, 3, 13))) |\n",
    "                ((row['date_post_min0'].date() >= datetime.date(2016, 11, 6)) & (row['date_post_min0'].date() < datetime.date(2017, 3, 12))) |\n",
    "                ((row['date_post_min0'].date() >= datetime.date(2017, 11, 5)) & (row['date_post_min0'].date() < datetime.date(2018, 3, 11)))):\n",
    "                \n",
    "                df_temp.loc[index, 'hour_24_local'] = df_temp.loc[index, 'hour_24_local'] - 1\n",
    "            \n",
    "            if df_temp.loc[index, 'hour_24_local'] < 0:\n",
    "                df_temp.loc[index, 'hour_24_local'] = df_temp.loc[index, 'hour_24_local'] + 24\n",
    "                df_temp.loc[index, 'date_post_min0'] = df_temp.loc[index, 'date_post_min0'] - pd.to_timedelta(1, unit = 'd')\n",
    "        else:\n",
    "            df_temp.loc[index, 'hour_24_local'] = -99\n",
    "\n",
    "    df_temp['hour_24_local'] = df_temp['hour_24_local'].astype('int64')\n",
    "\n",
    "    # create year-month\n",
    "    \n",
    "    df_temp['year_month'] = df_temp['date_post_min0'].apply(lambda x: x.year) * 100 + df_temp['date_post_min0'].apply(lambda x: x.month)\n",
    "    df_temp['month'] = df_temp['date_post_min0'].apply(lambda x: x.month)\n",
    "    df_temp['quarter'] = df_temp['date_post_min0'].dt.quarter\n",
    "        \n",
    "    df_temp.drop(['date_post', 'followers_account', 'description', 'title_info', 'time_post', 'video_link', 'image_link'], axis = 1, inplace = True)\n",
    "\n",
    "    number_pictures_before = df_temp.shape[0]\n",
    "    print('The number of pictures of', account_04[i][1], 'before merging to the weather data is', number_pictures_before)\n",
    "    \n",
    "    # PRCP = Precipitation (inches)\n",
    "    # TMAX = Maximum temperature (degrees Fahrenheit)\n",
    "    # TMIN = Minimum temperature (degrees Fahrenheit)\n",
    "    \n",
    "    weather_data = pd.read_csv('weather_data/weather_' + str(account_04[i][2]) + '.csv', parse_dates = [5], dayfirst = True, low_memory = False)\n",
    "    weather_data['latitude_resort'] = account_04[i][4]\n",
    "    weather_data['longitude_resort'] = account_04[i][3]\n",
    "    weather_data['min_elevation'] = account_04[i][5]\n",
    "    weather_data['max_elevation'] = account_04[i][6]\n",
    "    \n",
    "    # there are some 'weird' values -> remove this low quality data (Alaska has some temperatures of -148 degrees F ...)\n",
    "    weather_data = weather_data[weather_data['TMAX'] > -147]\n",
    "    weather_data = weather_data[weather_data['TMIN'] > -147]\n",
    "\n",
    "    # remove duplicates\n",
    "    weather_data.drop_duplicates(keep = 'first', inplace = True)\n",
    "    \n",
    "    # calculate the distance from the resort to every weather station in the file\n",
    "    \n",
    "    def haversine(lon1, lat1, lon2, lat2):\n",
    "\n",
    "        # convert decimal degrees to radians\n",
    "        lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "        \n",
    "        # haversine formula\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "        c = 2 * asin(sqrt(a))\n",
    "        r = 6371 # radius of earth in kilometers (use 3956 for miles)\n",
    "        \n",
    "        return c * r\n",
    "    \n",
    "    weather_data['DISTANCE'] = weather_data.apply(lambda row: haversine(lon1 = row['LONGITUDE'],\n",
    "                                                                        lat1 = row['LATITUDE'],\n",
    "                                                                        lon2 = row['longitude_resort'],\n",
    "                                                                        lat2 = row['latitude_resort']), axis = 1)\n",
    "    \n",
    "    # calculate the difference in elevation between the weather station and mid-mountain of the resort,\n",
    "    # a positive number indicates a higher elevation of the weather station\n",
    "    weather_data['ELEVATION_DIFFERENCE'] = (weather_data['ELEVATION'] - ((weather_data['max_elevation'] + weather_data['min_elevation']) / 2)) / 1000\n",
    "\n",
    "    weather_data['DATE'] = pd.to_datetime(weather_data['DATE'])\n",
    "    weather_data = weather_data[['STATION', 'DATE', 'PRCP', 'TMAX', 'TMIN', 'DISTANCE', 'ELEVATION_DIFFERENCE']]\n",
    "    weather_data.columns = ['station', 'date', 'precipitation_inches', 'temp_max', 'temp_min', 'distance', 'elevation_difference']\n",
    "\n",
    "    # convert precipitation to mm and temperatures to degrees Celsius\n",
    "    weather_data['precipitation_mm'] = weather_data['precipitation_inches'] * 2.54 * 10\n",
    "    weather_data['temp_max_celsius'] = (weather_data['temp_max'] - 32) * 5 / 9\n",
    "    weather_data['temp_min_celsius'] = (weather_data['temp_min'] - 32) * 5 / 9\n",
    "\n",
    "    account_stats_resort = pd.DataFrame()\n",
    "    \n",
    "    # add weather statistics for days before posting\n",
    "    for k in range(0, 4):\n",
    "        if k > 0:\n",
    "            df_temp['date_post_min' + str(k)] = df_temp['date_post_min0'] - pd.to_timedelta(k, unit = 'd')\n",
    "        \n",
    "        weather_stats = ['precipitation_mm', 'temp_max_celsius', 'temp_min_celsius']\n",
    "        \n",
    "        for weather_stat in weather_stats:\n",
    "            \n",
    "            # select closest available observation\n",
    "            min_per_day = weather_data[weather_data[weather_stat].notnull()].groupby('date')['distance'].min().to_frame().reset_index()\n",
    "            \n",
    "            weather_data_optimum = weather_data.merge(min_per_day,\n",
    "                                                      left_on = ['date', 'distance'],\n",
    "                                                      right_on = ['date', 'distance'],\n",
    "                                                      how = 'inner')\n",
    "            \n",
    "            # remove missing values\n",
    "            weather_data_optimum = weather_data_optimum[weather_data_optimum[weather_stat].notnull()]\n",
    "            \n",
    "            # in case duplicates still exist, let's keep the largest value\n",
    "            weather_data_optimum.sort_values(by = ['date', 'distance', 'elevation_difference', weather_stat], ascending = False, inplace = True)\n",
    "            weather_data_optimum.drop_duplicates(subset = ['date', 'distance', 'elevation_difference'], keep = 'first', inplace = True)\n",
    "            \n",
    "            weather_data_optimum = weather_data_optimum[['date', 'distance', 'elevation_difference', weather_stat]]\n",
    "            \n",
    "            # correct the temperature for the difference in elevation (6 degrees celsius per 1000 meters)\n",
    "            if (weather_stat == 'temp_max_celsius') | (weather_stat == 'temp_min_celsius'):\n",
    "                weather_data_optimum[weather_stat] = weather_data_optimum[weather_stat] + weather_data_optimum['elevation_difference'] * 6\n",
    "\n",
    "            df_temp = df_temp.merge(weather_data_optimum,\n",
    "                                    left_on = 'date_post_min' + str(k),\n",
    "                                    right_on = 'date',\n",
    "                                    how = 'left')\n",
    "\n",
    "            df_temp.rename(columns = {weather_stat: weather_stat + '_min' + str(k)}, inplace = True)   \n",
    "            \n",
    "            # save both minimum and maximum distance as well as minimum and maximum elevation difference per weather statistic \n",
    "            min_distance = df_temp['distance'].min()\n",
    "            max_distance = df_temp['distance'].max()\n",
    "            \n",
    "            account_stats_temp = [account_04[i][1],\n",
    "                                  weather_stat + '_min' + str(k),\n",
    "                                  min_distance,\n",
    "                                  max_distance]\n",
    "\n",
    "            account_stats_temp_df = pd.DataFrame(account_stats_temp).T\n",
    "        \n",
    "            account_stats_resort = pd.concat([account_stats_resort, account_stats_temp_df], axis = 0)\n",
    "        \n",
    "            df_temp.drop(['date', 'distance', 'elevation_difference'], axis = 1, inplace = True)\n",
    "            \n",
    "    # add weather statistics for days before posting\n",
    "    for k in range(1, 4):\n",
    "        df_temp['date_post_plus' + str(k)] = df_temp['date_post_min0'] + pd.to_timedelta(k, unit = 'd')\n",
    "        \n",
    "        weather_stats = ['precipitation_mm', 'temp_max_celsius', 'temp_min_celsius']\n",
    "        \n",
    "        for weather_stat in weather_stats:\n",
    "                        \n",
    "            # select closest available observation\n",
    "            min_per_day = weather_data[weather_data[weather_stat].notnull()].groupby('date')['distance'].min().to_frame().reset_index()\n",
    "            \n",
    "            weather_data_optimum = weather_data.merge(min_per_day,\n",
    "                                                      left_on = ['date', 'distance'],\n",
    "                                                      right_on = ['date', 'distance'],\n",
    "                                                      how = 'inner')\n",
    "            \n",
    "            # remove missing values\n",
    "            weather_data_optimum = weather_data_optimum[weather_data_optimum[weather_stat].notnull()]\n",
    "            \n",
    "            # in case duplicates still exist, let's keep the largest value\n",
    "            weather_data_optimum.sort_values(by = ['date', 'distance', 'elevation_difference', weather_stat], ascending = False, inplace = True)\n",
    "            weather_data_optimum.drop_duplicates(subset = ['date', 'distance', 'elevation_difference'], keep = 'first', inplace = True)\n",
    "\n",
    "            weather_data_optimum = weather_data_optimum[['date', 'distance', 'elevation_difference', weather_stat]]\n",
    "            \n",
    "            # correct the temperature for the difference in elevation (6 degrees celsius per 1000 meters)\n",
    "            if (weather_stat == 'temp_max_celsius') | (weather_stat == 'temp_min_celsius'):\n",
    "                weather_data_optimum[weather_stat] = weather_data_optimum[weather_stat] + weather_data_optimum['elevation_difference'] * 6\n",
    "\n",
    "            df_temp = df_temp.merge(weather_data_optimum,\n",
    "                                    left_on = 'date_post_plus' + str(k),\n",
    "                                    right_on = 'date',\n",
    "                                    how = 'left')\n",
    "\n",
    "            df_temp.rename(columns = {weather_stat: weather_stat + '_plus' + str(k)}, inplace = True)   \n",
    "            \n",
    "            # save both minimum and maximum distance as well as minimum and maximum elevation difference per weather statistic \n",
    "            min_distance = df_temp['distance'].min()\n",
    "            max_distance = df_temp['distance'].max() \n",
    "            \n",
    "            account_stats_temp = [account_04[i][1],\n",
    "                                  weather_stat + '_plus' + str(k),\n",
    "                                  min_distance,\n",
    "                                  max_distance]\n",
    "    \n",
    "            account_stats_temp_df = pd.DataFrame(account_stats_temp).T\n",
    "        \n",
    "            account_stats_resort = pd.concat([account_stats_resort, account_stats_temp_df], axis = 0)\n",
    "        \n",
    "            df_temp.drop(['date', 'distance', 'elevation_difference'], axis = 1, inplace = True)\n",
    "            \n",
    "    number_pictures_after = df_temp.shape[0]\n",
    "    print('The number of pictures of', account_04[i][1], 'after merging to the weather data is', number_pictures_after)\n",
    "    \n",
    "    # print the number of missings in the data\n",
    "    print('There are', df_temp.isnull().sum().sum(), 'missings.')\n",
    "\n",
    "    df_01 = pd.concat([df_01, df_temp], axis = 0)\n",
    "    account_stats_total = pd.concat([account_stats_total, account_stats_resort], axis = 0)\n",
    "\n",
    "    # if the number of records is different than before the analysis, the program will stop\n",
    "    if number_pictures_before == number_pictures_after:\n",
    "        print('   OK!\\n')\n",
    "    else:\n",
    "        exit()\n",
    "\n",
    "account_stats_total.columns = ['resort',\n",
    "                               'weather statistic',\n",
    "                               'minimum distance',\n",
    "                               'maximum distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final check: does the dataset contain duplicates?\n",
    "[g for _, g in df_01.groupby(\"image_id\") if len(g) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the maximum distance per resort\n",
    "account_stats_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the statistics to a csv\n",
    "account_stats_total.to_csv('results/account_statistics_pictures.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the shape of the dataset?\n",
    "df_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the oldest and newest picture for each resort\n",
    "df_min = df_01.groupby('resort')['date_post_min0'].min().to_frame()\n",
    "df_min.rename(columns = {'date_post_min0': 'first_post'}, inplace = True)\n",
    "df_max = df_01.groupby('resort')['date_post_min0'].max().to_frame()\n",
    "df_max.rename(columns = {'date_post_min0': 'last_post'}, inplace = True)\n",
    "df_date = pd.merge(df_min, df_max, left_index = True, right_index = True)\n",
    "\n",
    "df_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many missings does the final dataframe have?\n",
    "df_01.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select pictures that have been online for at least 10 days\n",
    "#    -> because several 'scraping batches' have been used, some pictures will have missing data otherwise\n",
    "#    -> 84 pictures will be removed\n",
    "\n",
    "df_02 = df_01[df_01['days_online'] >= 10]\n",
    "\n",
    "print('Number of pictures in df_01:', df_01.shape[0])\n",
    "print('Number of pictures in df_02:', df_02.shape[0])\n",
    "print('Number of missing values in df_02:', df_02.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview of the dataset\n",
    "df_02.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the final dataframe to a csv\n",
    "df_02.to_csv('results/picture_specific_dataset.csv', sep = ',', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
