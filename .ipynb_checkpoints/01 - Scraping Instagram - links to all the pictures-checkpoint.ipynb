{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "import selenium.webdriver as webdriver\n",
    "import urllib\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "\n",
    "account =  ['resortalyeska',\n",
    "            'skiheavenly',\n",
    "            'kirkwoodmtn',\n",
    "            'mammothmountain',\n",
    "            'northstar_california',\n",
    "            'squawalpine',\n",
    "            'sugarbowlresort',\n",
    "            'arapahoe_basin',\n",
    "            'aspensnowmass',\n",
    "            'aspenco',\n",
    "            'beavercreek',\n",
    "            'breckenridgemtn',\n",
    "            'coppermtn',\n",
    "            'skicrestedbutte',\n",
    "            'keystone_resort',\n",
    "            'lovelandskiarea',\n",
    "            'skipowderhorn',\n",
    "            'silvertonmtn',\n",
    "            'steamboatresort',\n",
    "            'tellurideski',\n",
    "            'vailmtn',\n",
    "            'winterparkresort',\n",
    "            'schweitzer_mountain',\n",
    "            'sunvalley',\n",
    "            'tamarackresort',\n",
    "            'bigskyresort',\n",
    "            'bridgerbowl',\n",
    "            'mtroseskitahoe',\n",
    "            'skitaos',\n",
    "            'mthoodmeadows',\n",
    "            'altaskiarea',\n",
    "            'brightonresort',\n",
    "            'deervalleyresort',\n",
    "            'pcski',\n",
    "            'powdermountain',\n",
    "            'snowbasinresort',\n",
    "            'snowbird',\n",
    "            'solitudemtn',\n",
    "            'jaypeakresort',\n",
    "            'killingtonmtn',\n",
    "            'madriverglen',\n",
    "            'stowemt',\n",
    "            'crystalmountain',\n",
    "            'mtbakerskiarea',\n",
    "            'stevenspass',           \n",
    "            'grandtargheeresort',\n",
    "            'jacksonhole',\n",
    "            'sundanceresort',\n",
    "            'bogusbasin',\n",
    "            'summitatsnoqualmie',\n",
    "            'skipurg',\n",
    "            'brianheadresort',\n",
    "            'sierra_at_tahoe',\n",
    "            'skieaglecrest',\n",
    "            'silvermountain',\n",
    "            'skisantafe',\n",
    "            'skithebeav',\n",
    "            'brundagemtn',\n",
    "            'skieaglepoint',\n",
    "            'whitepass',\n",
    "            'losttrailskiarea',\n",
    "            'smugglersnotchvt',\n",
    "            'redlodge',\n",
    "            'monarchmountain',\n",
    "            'sugarbush_vt',\n",
    "            'skiwhitefish',\n",
    "            'wolfcreekski',\n",
    "            'mtbachelor',      \n",
    "            'whistlerblackcomb',\n",
    "            'revelstoke',\n",
    "            'ferniealpineresort',\n",
    "            'whitewaterskiresort',\n",
    "            'redresort',\n",
    "            'sunshinevillage',\n",
    "            'kickinghorsemtn',\n",
    "            'powderkingmountainresort',\n",
    "            'skilouise',\n",
    "            'panoramaresort',\n",
    "            'castlemountainresort',\n",
    "            'skibigwhite',\n",
    "            'cypressmtn',\n",
    "            'silverstarmtnresort',\n",
    "            'sunpeaksresort',\n",
    "            'mountwashington',\n",
    "            'timberlinelodge',\n",
    "            'skihomewood',\n",
    "            'eldoramtnresort',\n",
    "            'bearvalleymountainupdates',\n",
    "            'diamondpeak',\n",
    "            '49degreesnorth',\n",
    "            'lookoutpass',\n",
    "            'discoveryskiarea',\n",
    "            'pebbleskiarea',\n",
    "            'sunlightmountainresort',\n",
    "            'skibowl',\n",
    "            'dodgeridge',\n",
    "            'anthonylakes',\n",
    "            'marmotbasin',\n",
    "            'apexmtnresort']\n",
    "\n",
    "for i in range(0, len(account)):\n",
    "    \n",
    "    lastheight = 0\n",
    "    \n",
    "    # open the VPN-connection and wait for 60 seconds for the program to actually connect\n",
    "    vpn = subprocess.Popen('c:\\\\Program Files\\\\Trust.Zone VPN Client\\\\trustzone_x64.exe')\n",
    "    time.sleep(60)\n",
    "\n",
    "    # collect and print the public IP address to make sure the VPN worked\n",
    "    public_ip = get('https://api.ipify.org').text\n",
    "    print('The public IP address is:',public_ip)\n",
    "    \n",
    "    # set the URL to the Instagram account\n",
    "    url = 'https://www.instagram.com/' + str(account[i])\n",
    "\n",
    "    # url: from which location are you going to scrape?\n",
    "    # path: remove the basic url (everything from the first single / will be in the path)\n",
    "    # folder_name: remove the / from path\n",
    "    # folder_path: create a path to store the results: images/folder_name\n",
    "\n",
    "    # make a folder to save the data\n",
    "    path = urllib.parse.urlparse(url).path\n",
    "    folder_name = path.replace('/', '')\n",
    "    folder_path = 'images/{}/'.format(folder_name)\n",
    "\n",
    "    # create the folder bases on folder_path\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print ('path created')\n",
    "\n",
    "    driver = webdriver.Firefox()\n",
    "    driver.get(url)\n",
    "    driver.set_window_size(1000, 600000)\n",
    "\n",
    "    # instagram shows a 'Load More' (depending on the language settings...)\n",
    "    # press this button to show the complete page and scroll to the bottom\n",
    "    \n",
    "    # wait 10 seconds for the page to load again and continue until the page doesn't reload anymore, when\n",
    "    # that happens go up a 1000 pixels in order for the page to reload and continue until it stops loading again\n",
    "\n",
    "    clickin = driver.find_element_by_link_text('Meer laden')\n",
    "\n",
    "    if clickin.click():\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    lastHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    scroll_count = 0\n",
    "    \n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(10)\n",
    "        newHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if newHeight == lastHeight:\n",
    "            scroll_count += 1\n",
    "            if scroll_count <= 1:\n",
    "                newHeight = lastHeight - 1000\n",
    "            else:\n",
    "                break\n",
    "        lastHeight = newHeight\n",
    "        \n",
    "    only_a_and_meta_tags = SoupStrainer(['a', 'meta'])\n",
    "\n",
    "    # parse the html of the resulting website into soup\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\", parse_only = only_a_and_meta_tags)\n",
    "    \n",
    "    # this will close the page once scraping is completed\n",
    "    driver.close()\n",
    "\n",
    "    # scrape the number of followers for each account\n",
    "    followers_account = str()\n",
    "\n",
    "    for link in soup.find_all('meta'):\n",
    "        metaprop = link.get('property')\n",
    "        if metaprop == \"og:description\":\n",
    "            description_info = link.get('content')\n",
    "            followers_account_str = re.search('\\d.+?(?=volgers|Followers)', str(description_info)).group(0).strip()\n",
    "\n",
    "            # get rid of the k or K (thousands) and commas and convert to integers\n",
    "            followers_account_temp = re.sub('[kK]+', '', followers_account_str)\n",
    "            if followers_account_temp == followers_account_str:\n",
    "                followers_account = int(float(re.sub('[,]+', '', followers_account_temp)))\n",
    "            else:\n",
    "                followers_account = int(float(re.sub('[,]+', '.', followers_account_temp)) * 1000)\n",
    "\n",
    "    # scrape the links to all the images of an account\n",
    "    image_url_list = []\n",
    "    \n",
    "    for link in soup.find_all('a'):\n",
    "        if str(link.get('href')).startswith('/p'):\n",
    "            m = [account[i], public_ip, \"http://www.instagram.com\" + str(link.get('href')), followers_account]\n",
    "            image_url_list.append(m)\n",
    "    \n",
    "    print('The number of pictures for', account[i], 'is:', len(image_url_list))\n",
    "    \n",
    "    account_images = pd.DataFrame([[x[0], x[1], x[2], x[3]] for x in image_url_list])\n",
    "    account_images.to_csv(os.path.join(folder_path, str(account[i]) + \"_pictures.csv\"), sep = ',', index = False)\n",
    "    \n",
    "    vpn.terminate()\n",
    "    time.sleep(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
